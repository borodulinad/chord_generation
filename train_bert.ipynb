{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Генерация аккордов в последовательности"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Задание заключается в написании модели BERT для генерации гитарных аккордов.\n",
        "\n",
        "В качестве данных взят датасет https://huggingface.co/datasets/lluccardoner/melodyGPT-song-chords-text-1.\n",
        "\n",
        "В этом ноутбуке присутствует:\n",
        "\n",
        "1) Очистка данных \n",
        "\n",
        "2) Аугментация\n",
        "\n",
        "3) Токенизатор\n",
        "\n",
        "4) Обучение модели"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YERDzx41QFNf"
      },
      "outputs": [],
      "source": [
        "# !pip install transformers datasets torch scikit-learn matplotlib seaborn streamlit plotly"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import polars as pl\n",
        "import math\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import random\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torch.optim import Adam\n",
        "from tqdm import tqdm\n",
        "import re\n",
        "from typing import List, Tuple, Optional, Mapping,  Self, NamedTuple\n",
        "import pandas as pd\n",
        "from datasets import load_dataset\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z1RK0xdIOA0c"
      },
      "outputs": [],
      "source": [
        "def load_and_clean_dataset():\n",
        "\n",
        "    dataset = load_dataset(\"lluccardoner/melodyGPT-song-chords-text-1\")\n",
        "    df = dataset['train'].to_pandas()\n",
        "\n",
        "    def clean_chords(text):\n",
        "        if not isinstance(text, str):\n",
        "            return \"\"\n",
        "\n",
        "        text = re.sub(r'\\t', ' ', text)\n",
        "        text = re.sub(r'\\b(INTRO|VERSE|CHORUS|BRIDGE|OUTRO|SOLO|PRE-CHORUS)\\b', '', text, flags=re.IGNORECASE)\n",
        "\n",
        "        chords = re.findall(r'[A-G][#b]?(?:m|maj|min|aug|dim|sus2|sus4)?(?:add)?[0-9]*(?:\\([0-9]+\\))?(?:\\/[A-G][#b]?)?', text.upper())\n",
        "\n",
        "        return ' '.join(chords)\n",
        "\n",
        "    df['cleaned_chords'] = df['chords_str'].apply(clean_chords)\n",
        "\n",
        "    df = df[df['cleaned_chords'].str.len() > 0]\n",
        "\n",
        "    return df\n",
        "\n",
        "\n",
        "class ChordTransposer:\n",
        "\n",
        "    def __init__(self):\n",
        "        self.chord_map = {\n",
        "            'C': 0, 'C#': 1, 'Db': 1, 'D': 2, 'D#': 3, 'Eb': 3,\n",
        "            'E': 4, 'F': 5, 'F#': 6, 'Gb': 6, 'G': 7, 'G#': 8,\n",
        "            'Ab': 8, 'A': 9, 'A#': 10, 'Bb': 10, 'B': 11\n",
        "        }\n",
        "        self.reverse_map = {v: k for k, v in self.chord_map.items()}\n",
        "\n",
        "        self.chord_patterns = [\n",
        "            # Аккорды с добавлениями в скобках: A5(9), C7(11)\n",
        "            r'([A-G][#b]?)(.*)(\\(.*\\))',\n",
        "            # Аккорды с add: Cadd9, Dmadd11\n",
        "            r'([A-G][#b]?)(.*)(add.*)',\n",
        "            # Аккорды с sus: Dsus4, Asus2\n",
        "            r'([A-G][#b]?)(.*)(sus.*)',\n",
        "            # Септаккорды и расширения: Cmaj7, G9, Am11\n",
        "            r'([A-G][#b]?)(.*)(\\d+)',\n",
        "            # Базовые аккорды: C, Dm, E7\n",
        "            r'([A-G][#b]?)(.*)'\n",
        "        ]\n",
        "\n",
        "    def transpose_chord(self, chord, steps):\n",
        "\n",
        "        for pattern in self.chord_patterns:\n",
        "            match = re.match(pattern, chord)\n",
        "            if match:\n",
        "                groups = match.groups()\n",
        "                tone = groups[0]\n",
        "\n",
        "                if tone in self.chord_map:\n",
        "\n",
        "                    new_tone_num = (self.chord_map[tone] + steps) % 12\n",
        "                    new_tone = self.reverse_map[new_tone_num]\n",
        "\n",
        "                    if len(groups) == 3:\n",
        "                        quality = groups[1] or ''\n",
        "                        extension = groups[2] or ''\n",
        "                        return new_tone + quality + extension\n",
        "                    else:\n",
        "                        quality = groups[1] or ''\n",
        "                        return new_tone + quality\n",
        "\n",
        "                break\n",
        "\n",
        "        return chord\n",
        "\n",
        "    def transpose_sequence(self, chord_sequence, steps):\n",
        "        chords = chord_sequence.split()\n",
        "        transposed = [self.transpose_chord(chord, steps) for chord in chords]\n",
        "        return ' '.join(transposed)\n",
        "\n",
        "def augment_dataset(df, num_transpositions=5):\n",
        "    transposer = ChordTransposer()\n",
        "    augmented_data = []\n",
        "\n",
        "    for _, row in df.iterrows():\n",
        "        chords = row['cleaned_chords']\n",
        "        if len(chords.split()) < 3:\n",
        "            continue\n",
        "\n",
        "        augmented_data.append({\n",
        "            'cleaned_chords': chords,\n",
        "            'genres': row.get('genres'),\n",
        "            'artist_name': row.get('artist_name', 'unknown'),\n",
        "            'song_name': row.get('song_name', 'unknown')\n",
        "        })\n",
        "\n",
        "        for steps in range(1, num_transpositions + 1):\n",
        "            transposed = transposer.transpose_sequence(chords, steps)\n",
        "            augmented_data.append({\n",
        "                'cleaned_chords': transposed,\n",
        "                'genres': row.get('genres'),\n",
        "                'artist_name': row.get('artist_name', 'unknown'),\n",
        "                'song_name': row.get('song_name', 'unknown')\n",
        "            })\n",
        "\n",
        "    return pd.DataFrame(augmented_data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "s_1oH9rXP2LF"
      },
      "outputs": [],
      "source": [
        "dataset = load_and_clean_dataset()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Аугментированный датасет, для обучения берется обычный датасет"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "ukXBwpovf0BX"
      },
      "outputs": [],
      "source": [
        "augmented_dataset = augment_dataset(dataset)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Токенайзер"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XirfHKjVOQXq"
      },
      "outputs": [],
      "source": [
        "class ChordTokenizer:\n",
        "    def __init__(self):\n",
        "        self._padding_token = \"[PAD]\"\n",
        "        self._unknown_token = \"[UNK]\"\n",
        "        self._cls_token = \"[CLS]\"\n",
        "        self._sep_token = \"[SEP]\"\n",
        "        self._mask_token = \"[MASK]\"\n",
        "        \n",
        "        # Special tokens IDs\n",
        "        self._padding_id = 0\n",
        "        self._cls_id = 1\n",
        "        self._sep_id = 2\n",
        "        self._mask_token_id = 3\n",
        "        self._unknown_token_id = 4\n",
        "        \n",
        "        # Музыкальные элементы\n",
        "        self.notes = ['C', 'C#', 'D', 'D#', 'E', 'F', 'F#', 'G', 'G#', 'A', 'A#', 'B']\n",
        "        self.moods = ['m', 'maj', 'min', 'aug', 'dim', 'sus2', 'sus4', 'sus']\n",
        "        self.extensions = [\n",
        "            '5', '6', '7', '9', '11', '13', \n",
        "            'add9', 'add11', 'add13'\n",
        "        ]\n",
        "        self.symbols = ['/', 'b', '#', '(', ')', ' ']\n",
        "        \n",
        "        # Сложные аккорды для добавления в словарь\n",
        "        self.complex_chords = [\n",
        "            'A5(9)', 'Cadd9', 'Dsus4', 'Emadd9', 'G5(11)',\n",
        "            'Fmaj7', 'G9', 'Am11', 'C7(9)', 'Dsus2',\n",
        "            'Cmaj9', 'F#m7', 'Bbmaj7', 'E7sus4', 'Aadd9'\n",
        "        ]\n",
        "        \n",
        "        self._init_vocab()\n",
        "\n",
        "    @property\n",
        "    def vocab(self) -> Mapping[int, str]:\n",
        "        return self._vocab\n",
        "    \n",
        "    @property\n",
        "    def reverse_vocab(self) -> Mapping[str, int]:\n",
        "        return {token: idx for idx, token in self._vocab.items()}\n",
        "    \n",
        "    @property\n",
        "    def cls_id(self) -> int:\n",
        "        return self._cls_id\n",
        "    \n",
        "    @property\n",
        "    def mask_token_id(self) -> int:\n",
        "        return self._mask_token_id\n",
        "    \n",
        "    @property\n",
        "    def padding_id(self) -> int:\n",
        "        return self._padding_id\n",
        "    \n",
        "    @property\n",
        "    def sep_id(self) -> int:\n",
        "        return self._sep_id\n",
        "    \n",
        "    @property\n",
        "    def unknown_token_id(self) -> int:\n",
        "        return self._unknown_token_id\n",
        "\n",
        "    def _init_vocab(self) -> None:\n",
        "        \"\"\"Инициализация словаря с специальными токенами\"\"\"\n",
        "        self._vocab = {\n",
        "            self._padding_id: self._padding_token,\n",
        "            self._cls_id: self._cls_token,\n",
        "            self._sep_id: self._sep_token,\n",
        "            self._mask_token_id: self._mask_token,\n",
        "            self._unknown_token_id: self._unknown_token,\n",
        "        }\n",
        "    \n",
        "    def fit(self, corpus: List[str]) -> Self:\n",
        "        \"\"\"Создание словаря на основе корпуса\"\"\"\n",
        "        self._init_vocab()\n",
        "        \n",
        "        # Добавляем базовые музыкальные элементы\n",
        "        all_elements = (self.notes + self.moods + self.extensions + \n",
        "                       self.symbols + self.complex_chords)\n",
        "        \n",
        "        for element in all_elements:\n",
        "            if element not in self._vocab.values():\n",
        "                self._vocab[len(self._vocab)] = element\n",
        "        \n",
        "        # Обрабатываем корпус для извлечения дополнительных аккордов\n",
        "        for text in corpus:\n",
        "            chords = text.split()\n",
        "            for chord in chords:\n",
        "                if chord not in self.reverse_vocab and chord not in self._vocab.values():\n",
        "                    self._vocab[len(self._vocab)] = chord\n",
        "        \n",
        "        return self\n",
        "    \n",
        "    def tokenize_text(self, text: str | List[str]) -> List[str] | List[List[str]]:\n",
        "        \"\"\"Токенизация текста в строковые токены\"\"\"\n",
        "        if isinstance(text, str):\n",
        "            return self._tokenize_text(text)\n",
        "        assert isinstance(text, list), \"`text` should be str or List[str]\"\n",
        "        return [self._tokenize_text(chunk) for chunk in text]\n",
        " \n",
        "    def tokenize_ids(self, text: str | List[str]) -> List[int] | List[List[int]]:\n",
        "        \"\"\"Токенизация текста в ID токенов\"\"\"\n",
        "        if isinstance(text, str):\n",
        "            return self._tokenize_ids(text)\n",
        "        assert isinstance(text, list), \"`text` should be str or List[str]\"\n",
        "        return [self._tokenize_ids(chunk) for chunk in text]\n",
        "    \n",
        "    def decode(self, tokens: List[int]) -> str:\n",
        "        \"\"\"Декодирование ID токенов обратно в строку\"\"\"\n",
        "        content = []\n",
        "        reverse_vocab = self.reverse_vocab\n",
        "        \n",
        "        for token_id in tokens:\n",
        "            if token_id in [self._padding_id, self._cls_id, self._sep_id, self._mask_token_id]:\n",
        "                continue\n",
        "            \n",
        "            token = self._vocab.get(token_id, self._unknown_token)\n",
        "            if token == self._unknown_token:\n",
        "                continue\n",
        "                \n",
        "            content.append(token)\n",
        "        \n",
        "        # Собираем аккорды из токенов\n",
        "        result = []\n",
        "        current_chord = []\n",
        "        \n",
        "        for token in content:\n",
        "            if token == ' ':\n",
        "                if current_chord:\n",
        "                    result.append(''.join(current_chord))\n",
        "                    current_chord = []\n",
        "            else:\n",
        "                current_chord.append(token)\n",
        "        \n",
        "        if current_chord:\n",
        "            result.append(''.join(current_chord))\n",
        "            \n",
        "        return ' '.join(result)\n",
        "\n",
        "    def _tokenize_text(self, text: str) -> List[str]:\n",
        "        \"\"\"Внутренний метод для токенизации строки в текстовые токены\"\"\"\n",
        "        tokens = [self._cls_token]\n",
        "        reverse_vocab = self.reverse_vocab\n",
        "        \n",
        "        chords = text.split()\n",
        "        \n",
        "        for i, chord in enumerate(chords):\n",
        "            # Пытаемся найти целый аккорд в словаре\n",
        "            if chord in reverse_vocab:\n",
        "                tokens.append(chord)\n",
        "            else:\n",
        "                # Разбиваем аккорд на составляющие\n",
        "                chord_parts = self._split_chord(chord)\n",
        "                for part in chord_parts:\n",
        "                    if part in reverse_vocab:\n",
        "                        tokens.append(part)\n",
        "                    else:\n",
        "                        tokens.append(self._unknown_token)\n",
        "            \n",
        "            # Добавляем пробел между аккордами (кроме последнего)\n",
        "            if i < len(chords) - 1:\n",
        "                tokens.append(' ')\n",
        "        \n",
        "        tokens.append(self._sep_token)\n",
        "        return tokens\n",
        "    \n",
        "    def _tokenize_ids(self, text: str) -> List[int]:\n",
        "        \"\"\"Внутренний метод для токенизации строки в ID токенов\"\"\"\n",
        "        text_tokens = self._tokenize_text(text)\n",
        "        reverse_vocab = self.reverse_vocab\n",
        "        return [reverse_vocab.get(token, self._unknown_token_id) for token in text_tokens]\n",
        "    \n",
        "    def _split_chord(self, chord: str) -> List[str]:\n",
        "        \"\"\"Разбивает аккорд на составляющие элементы\"\"\"\n",
        "        # Регулярное выражение для разбора аккордов\n",
        "        pattern = r'[A-G][#b]?|[a-z]+|\\d+|[\\/\\(\\)#b]'\n",
        "        parts = re.findall(pattern, chord)\n",
        "        return parts\n",
        "    \n",
        "    def __len__(self) -> int:\n",
        "        return len(self._vocab)\n",
        "\n",
        "\n",
        "# Адаптер для Hugging Face (обновленная версия)\n",
        "class ChordTokenizerHF:\n",
        "    def __init__(self, chord_tokenizer: ChordTokenizer):\n",
        "        self.chord_tokenizer = chord_tokenizer\n",
        "\n",
        "    def __call__(self, texts, padding=True, truncation=True, max_length=128, return_tensors=None):\n",
        "        if isinstance(texts, str):\n",
        "            texts = [texts]\n",
        "\n",
        "        input_ids = []\n",
        "        attention_masks = []\n",
        "\n",
        "        for text in texts:\n",
        "            token_ids = self.chord_tokenizer.tokenize_ids(text)\n",
        "            \n",
        "            # Обрезаем если нужно\n",
        "            if truncation and len(token_ids) > max_length:\n",
        "                token_ids = token_ids[:max_length]\n",
        "\n",
        "            attention_mask = [1] * len(token_ids)\n",
        "\n",
        "            # Добавляем паддинг если нужно\n",
        "            if padding:\n",
        "                padding_length = max_length - len(token_ids)\n",
        "                token_ids = token_ids + [self.chord_tokenizer.padding_id] * padding_length\n",
        "                attention_mask = attention_mask + [0] * padding_length\n",
        "\n",
        "            input_ids.append(token_ids)\n",
        "            attention_masks.append(attention_mask)\n",
        "\n",
        "        output = {\n",
        "            'input_ids': input_ids,\n",
        "            'attention_mask': attention_masks\n",
        "        }\n",
        "\n",
        "        if return_tensors == 'pt':\n",
        "            import torch\n",
        "            output['input_ids'] = torch.tensor(output['input_ids'])\n",
        "            output['attention_mask'] = torch.tensor(output['attention_mask'])\n",
        "\n",
        "        return output\n",
        "\n",
        "    def decode(self, token_ids: List[int]) -> str:\n",
        "        \"\"\"Декодирование ID токенов обратно в строку\"\"\"\n",
        "        return self.chord_tokenizer.decode(token_ids)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Обучаем токенайзер"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<__main__.ChordTokenizer at 0x7f53fb817890>"
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "tokenizer = ChordTokenizer()\n",
        "corpus = dataset['cleaned_chords'].to_list()\n",
        "tokenizer.fit(corpus)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Подготовка данных к обучению"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "class TrainingBatch(NamedTuple):\n",
        "    input: torch.LongTensor\n",
        "    label: torch.LongTensor\n",
        "    segment_label: torch.LongTensor\n",
        "    is_next: torch.LongTensor\n",
        "\n",
        "class ChordDataset(Dataset):\n",
        "    def __init__(\n",
        "        self,\n",
        "        corpus: List[str],\n",
        "        fitted_tokenizer: ChordTokenizer,\n",
        "        max_seq_len: int = 128,\n",
        "        mask_prob: float = 0.15\n",
        "    ):\n",
        "        self.corpus = corpus\n",
        "        self.tokenizer = fitted_tokenizer\n",
        "        self.max_seq_len = max_seq_len\n",
        "        self.mask_prob = mask_prob\n",
        "        \n",
        "        # ID специальных токенов\n",
        "        self._pad_id = fitted_tokenizer.padding_id\n",
        "        self._cls_id = fitted_tokenizer.cls_id\n",
        "        self._sep_id = fitted_tokenizer.sep_id\n",
        "        self._mask_id = fitted_tokenizer.mask_token_id\n",
        "        self._unk_id = fitted_tokenizer.unknown_token_id\n",
        "        self._vocab_size = len(fitted_tokenizer.vocab)\n",
        "        \n",
        "        self._sequences = self._prepare_sequences()\n",
        "        \n",
        "    def _prepare_sequences(self) -> List[List[str]]:\n",
        "        sequences = []\n",
        "        for chord_progression in self.corpus:\n",
        "            chords = chord_progression.split()\n",
        "            for i in range(0, len(chords), self.max_seq_len // 2):\n",
        "                sequence = chords[i:i + self.max_seq_len // 2]\n",
        "                if len(sequence) >= 2:\n",
        "                    sequences.append(sequence)\n",
        "        return sequences\n",
        "    \n",
        "    def __len__(self) -> int:\n",
        "        return len(self._sequences)\n",
        "    \n",
        "    def __getitem__(self, idx: int) -> TrainingBatch:\n",
        "        seq1, seq2, is_next_label = self._get_next_sentence_pair(idx)\n",
        "        \n",
        "        seq1_masked, seq1_labels = self._mask_chords(seq1)\n",
        "        seq2_masked, seq2_labels = self._mask_chords(seq2)\n",
        "        \n",
        "        bert_input, bert_labels, segment_labels = self._prepare_bert_input(\n",
        "            seq1_masked, seq2_masked, seq1_labels, seq2_labels\n",
        "        )\n",
        "        \n",
        "        return TrainingBatch(\n",
        "            input=torch.LongTensor(bert_input),\n",
        "            label=torch.LongTensor(bert_labels),\n",
        "            segment_label=torch.LongTensor(segment_labels),\n",
        "            is_next=torch.LongTensor([is_next_label]),\n",
        "        )\n",
        "    \n",
        "    def _get_next_sentence_pair(self, idx: int) -> Tuple[List[str], List[str], int]:\n",
        "        prob = random.random()\n",
        "        \n",
        "        if prob < 0.5:\n",
        "            sequence = self._sequences[idx]\n",
        "            if len(sequence) >= 4:\n",
        "                split_point = len(sequence) // 2\n",
        "                seq1 = sequence[:split_point]\n",
        "                seq2 = sequence[split_point:split_point + len(seq1)]\n",
        "                return seq1, seq2, 1\n",
        "            else:\n",
        "                return sequence, sequence, 1\n",
        "        \n",
        "        seq1 = self._sequences[idx]\n",
        "        second_idx = random.randrange(len(self._sequences))\n",
        "        while second_idx == idx:\n",
        "            second_idx = random.randrange(len(self._sequences))\n",
        "        seq2 = self._sequences[second_idx]\n",
        "        \n",
        "        min_len = min(len(seq1), len(seq2))\n",
        "        seq1 = seq1[:min_len]\n",
        "        seq2 = seq2[:min_len]\n",
        "        \n",
        "        return seq1, seq2, 0\n",
        "    \n",
        "    def _mask_chords(self, chords: List[str]) -> Tuple[List[str], List[str]]:\n",
        "        masked_chords = []\n",
        "        labels = []\n",
        "        \n",
        "        for chord in chords:\n",
        "            prob = random.random()\n",
        "            \n",
        "            if prob < self.mask_prob:\n",
        "                if random.random() < 0.8:\n",
        "                    masked_chords.append(self.tokenizer._mask_token)\n",
        "                elif random.random() < 0.9:\n",
        "                    random_chord = random.choice(list(self.tokenizer.reverse_vocab.keys()))\n",
        "                    while random_chord in [self.tokenizer._padding_token, self.tokenizer._cls_token, \n",
        "                                         self.tokenizer._sep_token, self.tokenizer._mask_token]:\n",
        "                        random_chord = random.choice(list(self.tokenizer.reverse_vocab.keys()))\n",
        "                    masked_chords.append(random_chord)\n",
        "                else:\n",
        "                    masked_chords.append(chord)\n",
        "                labels.append(chord)\n",
        "            else:\n",
        "                masked_chords.append(chord)\n",
        "                labels.append(self.tokenizer._padding_token)\n",
        "        \n",
        "        return masked_chords, labels\n",
        "    \n",
        "    def _prepare_bert_input(self, seq1: List[str], seq2: List[str], \n",
        "                          labels1: List[str], labels2: List[str]) -> Tuple[List[int], List[int], List[int], List[int]]:\n",
        "        seq1_ids = self._chords_to_ids(seq1)\n",
        "        seq2_ids = self._chords_to_ids(seq2)\n",
        "        labels1_ids = self._chords_to_ids(labels1)\n",
        "        labels2_ids = self._chords_to_ids(labels2)\n",
        "        \n",
        "        bert_input = [self._cls_id] + seq1_ids + [self._sep_id] + seq2_ids + [self._sep_id]\n",
        "        bert_labels = [self._pad_id] + labels1_ids + [self._pad_id] + labels2_ids + [self._pad_id]\n",
        "        \n",
        "        segment_labels = [0] * (1 + len(seq1_ids) + 1)\n",
        "        segment_labels += [1] * (len(seq2_ids) + 1)\n",
        "        \n",
        "        \n",
        "        if len(bert_input) > self.max_seq_len:\n",
        "            bert_input = bert_input[:self.max_seq_len]\n",
        "            bert_labels = bert_labels[:self.max_seq_len]\n",
        "            segment_labels = segment_labels[:self.max_seq_len]\n",
        "        \n",
        "        padding_len = self.max_seq_len - len(bert_input)\n",
        "        if padding_len > 0:\n",
        "            bert_input += [self._pad_id] * padding_len\n",
        "            bert_labels += [self._pad_id] * padding_len\n",
        "            last_segment = segment_labels[-1] if segment_labels else 0\n",
        "            segment_labels += [last_segment] * padding_len\n",
        "        \n",
        "        return bert_input, bert_labels, segment_labels\n",
        "    \n",
        "    def _chords_to_ids(self, chords: List[str]) -> List[int]:\n",
        "        ids = []\n",
        "        for chord in chords:\n",
        "            if chord in self.tokenizer.reverse_vocab:\n",
        "                ids.append(self.tokenizer.reverse_vocab[chord])\n",
        "            else:\n",
        "                ids.append(self._unk_id)\n",
        "        return ids"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Далее классы из учебного ноутбука"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 147,
      "metadata": {},
      "outputs": [],
      "source": [
        "class ScheduledOptim():\n",
        "    '''A simple wrapper class for learning rate scheduling'''\n",
        "\n",
        "    def __init__(\n",
        "        self,\n",
        "        optimizer: torch.optim.Optimizer,\n",
        "        embedding_size: int,\n",
        "        n_warmup_steps,\n",
        "    ):\n",
        "        self._optimizer = optimizer\n",
        "        self.n_warmup_steps = n_warmup_steps\n",
        "        self.n_current_steps = 0\n",
        "        self.init_lr = np.power(embedding_size, -0.5)\n",
        "\n",
        "    def step_and_update_lr(self):\n",
        "        \"Step with the inner optimizer\"\n",
        "        self._update_learning_rate()\n",
        "        self._optimizer.step()\n",
        "\n",
        "    def zero_grad(self):\n",
        "        \"Zero out the gradients by the inner optimizer\"\n",
        "        self._optimizer.zero_grad()\n",
        "\n",
        "    def _get_lr_scale(self):\n",
        "        return np.min([\n",
        "            np.power(self.n_current_steps, -0.5),\n",
        "            np.power(self.n_warmup_steps, -1.5) * self.n_current_steps])\n",
        "\n",
        "    def _update_learning_rate(self):\n",
        "        ''' Learning rate scheduling per step '''\n",
        "\n",
        "        self.n_current_steps += 1\n",
        "        lr = self.init_lr * self._get_lr_scale()\n",
        "\n",
        "        for param_group in self._optimizer.param_groups:\n",
        "            param_group['lr'] = lr"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 148,
      "metadata": {},
      "outputs": [],
      "source": [
        "class RotaryPositionEmbedding(nn.Module):\n",
        "    def __init__(\n",
        "        self,\n",
        "        embedding_size: int,\n",
        "        base: int = 10_000,\n",
        "    ) -> None:\n",
        "        super().__init__()\n",
        "        self._theta = 1 / (torch.pow(torch.tensor(base), (torch.arange(0, embedding_size, 2).float() / embedding_size)))\n",
        "        self._theta = self._theta.repeat_interleave(2)\n",
        "        \n",
        "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
        "        position_ids = torch.arange(0, x.size(-2), device=x.device)\n",
        "        position_matrix = torch.outer(position_ids, self._theta.to(x.device))\n",
        "        cos = torch.cos(position_matrix)\n",
        "        sin = torch.sin(position_matrix)\n",
        "        x_odd = x[..., ::2]\n",
        "        x_even = x[..., 1::2]\n",
        "\n",
        "        _x = torch.empty_like(x, device=x.device)\n",
        "        _x[..., 0::2] = -x_even\n",
        "        _x[..., 1::2] = x_odd\n",
        "\n",
        "        # x_stacked = torch.stack([-x_even, x_odd], dim=-1)\n",
        "        # _x = x_stacked.flatten(start_dim=-2)\n",
        "        _x = _x * sin[:x.size(-2), :]\n",
        "        x = x * cos[:x.size(-2), :]\n",
        "        return x + _x\n",
        "\n",
        "class BERTEmbedding(nn.Module):\n",
        "    def __init__(\n",
        "        self,\n",
        "        vocab_size: int,\n",
        "        embedding_size: int,\n",
        "        dropout: float = 0.1,\n",
        "    ) -> None:\n",
        "        super().__init__()\n",
        "        self._embeddings = nn.Embedding(\n",
        "            num_embeddings=vocab_size,\n",
        "            embedding_dim=embedding_size,\n",
        "            padding_idx=0,\n",
        "        )\n",
        "        self._segment_embeddings = nn.Embedding(\n",
        "            num_embeddings=3,\n",
        "            embedding_dim=embedding_size,\n",
        "            padding_idx=0,\n",
        "        )\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        \n",
        "    def forward(self, x: torch.LongTensor, segmet_label: torch.LongTensor) -> torch.Tensor:\n",
        "        x = self._embeddings(x) + self._segment_embeddings(segmet_label)\n",
        "        return self.dropout(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 149,
      "metadata": {},
      "outputs": [],
      "source": [
        "class RoPEMultiHeadedAttention(nn.Module):\n",
        "    def __init__(\n",
        "        self,\n",
        "        num_heads: int,\n",
        "        embedding_size: int,\n",
        "        head_embedding_size: int,\n",
        "        positional_embedding: RotaryPositionEmbedding,\n",
        "        dropout: float = 0.1,\n",
        "    ):\n",
        "        super().__init__()\n",
        "        self._num_heads = num_heads\n",
        "        self._embedding_size = embedding_size\n",
        "        self._head_embedding_size = head_embedding_size\n",
        "        self._positional_embedding = positional_embedding\n",
        "        self._Q = nn.Linear(self._embedding_size, self._num_heads * self._head_embedding_size)\n",
        "        self._K = nn.Linear(self._embedding_size, self._num_heads * self._head_embedding_size)\n",
        "        self._V = nn.Linear(self._embedding_size, self._num_heads * self._head_embedding_size)\n",
        "        self._W_proj = nn.Linear(self._num_heads * self._head_embedding_size, self._embedding_size)\n",
        "        self._dropout = nn.Dropout(p=dropout)\n",
        "        self._layernorm = nn.LayerNorm(self._embedding_size)\n",
        "\n",
        "    def forward(\n",
        "        self,\n",
        "        query: torch.Tensor,\n",
        "        key: torch.Tensor,\n",
        "        value: torch.Tensor,\n",
        "        mask: Optional[torch.Tensor] = None,\n",
        "    ) -> torch.Tensor:\n",
        "        batch_size = query.size(0)\n",
        "\n",
        "        q = self._Q.forward(query).view(batch_size, -1, self._num_heads, self._head_embedding_size).transpose(1, 2)\n",
        "        k = self._K.forward(key).view(batch_size, -1, self._num_heads, self._head_embedding_size).transpose(1, 2)\n",
        "        v = self._V.forward(value).view(batch_size, -1, self._num_heads, self._head_embedding_size).transpose(1, 2)\n",
        "\n",
        "        q_rope = self._positional_embedding.forward(q)\n",
        "        k_rope = self._positional_embedding.forward(k)\n",
        "\n",
        "        attention_numerator = torch.exp(\n",
        "            torch.matmul(q_rope, k_rope.transpose(-1, -2)) / torch.sqrt(torch.tensor(self._head_embedding_size))\n",
        "        )\n",
        "        attention_denominator = torch.exp(\n",
        "            torch.matmul(q, k.transpose(-1, -2)) / torch.sqrt(torch.tensor(self._head_embedding_size))\n",
        "        )\n",
        "        attention_denominator = torch.sum(attention_denominator, dim=-1, keepdim=True)\n",
        "        a = attention_numerator / attention_denominator\n",
        "        # a = torch.matmul(q_rope, k_rope.transpose(-1, -2)) / torch.sqrt(torch.tensor(self._head_embedding_size))\n",
        "        if mask is not None:\n",
        "            # mask = mask.unsqueeze(1)\n",
        "            a = a.masked_fill(mask == 0, -torch.inf)\n",
        "        \n",
        "        alpha = F.softmax(a, -1)\n",
        "\n",
        "        z = torch.matmul(alpha, v).transpose(1, 2).contiguous().view(batch_size, -1, self._num_heads * self._head_embedding_size)\n",
        "        z = self._W_proj(z)\n",
        "        return self._layernorm(query + self._dropout(z))\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 150,
      "metadata": {},
      "outputs": [],
      "source": [
        "class FCNNBlock(nn.Module):\n",
        "    def __init__(\n",
        "        self,\n",
        "        embedding_size: int,\n",
        "        hidden_size: int,\n",
        "        dropout: float = 0.1,\n",
        "    ) -> None:\n",
        "        super().__init__()\n",
        "        self._linear1 = nn.Linear(embedding_size, hidden_size, bias=False)\n",
        "        self._linear2 = nn.Linear(hidden_size, embedding_size, bias=False)\n",
        "        self._activation = nn.GELU()\n",
        "        self._layernorm = nn.LayerNorm(embedding_size)\n",
        "        self._dropout = nn.Dropout(dropout)\n",
        "        \n",
        "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
        "        z = self._linear2(self._activation(self._linear1(x)))\n",
        "        return self._layernorm(x + self._dropout(z))\n",
        "\n",
        "class EncoderLayer(nn.Module):\n",
        "    def __init__(\n",
        "        self,\n",
        "        embedding_size: int,\n",
        "        num_heads: int,\n",
        "        head_embedding_size: int,\n",
        "        fcnn_hidden_size: int,\n",
        "        positional_embedding: RotaryPositionEmbedding,\n",
        "        dropout: float = 0.1,\n",
        "    ) -> None:\n",
        "        super().__init__()\n",
        "        self._mha = RoPEMultiHeadedAttention(\n",
        "            embedding_size=embedding_size,\n",
        "            num_heads=num_heads,\n",
        "            head_embedding_size=head_embedding_size,\n",
        "            positional_embedding=positional_embedding,\n",
        "            dropout=dropout,\n",
        "        )\n",
        "        self._fcnn = FCNNBlock(\n",
        "            embedding_size=embedding_size,\n",
        "            hidden_size=fcnn_hidden_size,\n",
        "            dropout=dropout,\n",
        "        )\n",
        "        \n",
        "    def forward(self, x: torch.Tensor, mask: Optional[torch.Tensor] = None) -> torch.Tensor:\n",
        "        return self._fcnn(self._mha(x, x, x, mask))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 151,
      "metadata": {},
      "outputs": [],
      "source": [
        "class Encoder(nn.Module):\n",
        "    def __init__(\n",
        "        self,\n",
        "        vocab_size: int,\n",
        "        n_layers: int,\n",
        "        embedding_size: int,\n",
        "        num_heads: int,\n",
        "        head_embedding_size: int,\n",
        "        fcnn_hidden_size: int,\n",
        "        dropout: float = 0.1,\n",
        "    ) -> None:\n",
        "        super().__init__()\n",
        "        self._vocab_size = vocab_size\n",
        "        self._embedding_size = embedding_size\n",
        "        self._embeddings = BERTEmbedding(\n",
        "            vocab_size=vocab_size,\n",
        "            embedding_size=embedding_size,\n",
        "            dropout=dropout,\n",
        "        )\n",
        "        self._positional_embeddings = RotaryPositionEmbedding(\n",
        "            embedding_size=head_embedding_size,\n",
        "            base=1000,\n",
        "        )\n",
        "        self._layers = nn.ModuleList(\n",
        "            EncoderLayer(\n",
        "                embedding_size=embedding_size,\n",
        "                num_heads=num_heads,\n",
        "                head_embedding_size=head_embedding_size,\n",
        "                fcnn_hidden_size=fcnn_hidden_size,\n",
        "                positional_embedding=self._positional_embeddings,\n",
        "                dropout=dropout,\n",
        "            )\n",
        "            for _ in range(n_layers)\n",
        "        )\n",
        "    \n",
        "    @property\n",
        "    def vocab_size(self) -> int:\n",
        "        return self._vocab_size\n",
        "    \n",
        "    @property\n",
        "    def embedding_size(self) -> int:\n",
        "        return self._embedding_size\n",
        "\n",
        "    def forward(\n",
        "        self,\n",
        "        x: torch.LongTensor,\n",
        "        segment: torch.LongTensor,\n",
        "    ) -> torch.Tensor:\n",
        "        mask = (x > 0).unsqueeze(1).repeat(1, x.size(1), 1).unsqueeze(1)\n",
        "        z = self._embeddings(x, segment)\n",
        "        for layer in self._layers:\n",
        "            z = layer(z, mask)\n",
        "        return z"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "class NextSentencePrediction(nn.Module):\n",
        "    \"\"\"\n",
        "    2-class classification model : is_next, is_not_next\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, embedding_size: int):\n",
        "        \"\"\"\n",
        "        :param hidden: BERT model output size\n",
        "        \"\"\"\n",
        "        super().__init__()\n",
        "        self._linear = nn.Linear(embedding_size, 2)\n",
        "        self._softmax = nn.LogSoftmax(dim=-1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # use only the first token which is the [CLS]\n",
        "        return self._softmax(self._linear(x[:, 0]))\n",
        "\n",
        "class MaskedLanguageModel(nn.Module):\n",
        "    \"\"\"\n",
        "    predicting origin token from masked input sequence\n",
        "    n-class classification problem, n-class = vocab_size\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, embedding_size: int, vocab_size: int):\n",
        "        \"\"\"\n",
        "        :param hidden: output size of BERT model\n",
        "        :param vocab_size: total vocab size\n",
        "        \"\"\"\n",
        "        super().__init__()\n",
        "        self._linear = nn.Linear(embedding_size, vocab_size)\n",
        "        self._softmax = nn.LogSoftmax(dim=-1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self._softmax(self._linear(x))\n",
        "\n",
        "class BERTLM(nn.Module):\n",
        "    \"\"\"\n",
        "    BERT Language Model\n",
        "    Next Sentence Prediction Model + Masked Language Model\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, encoder: Encoder):\n",
        "        \"\"\"\n",
        "        :param bert: BERT model which should be trained\n",
        "        :param vocab_size: total vocab size for masked_lm\n",
        "        \"\"\"\n",
        "\n",
        "        super().__init__()\n",
        "        self._encoder = encoder\n",
        "        self._next_sentence = NextSentencePrediction(self._encoder.embedding_size)\n",
        "        self._mask_lm = MaskedLanguageModel(self._encoder.embedding_size, self._encoder.vocab_size)\n",
        "\n",
        "    def forward(\n",
        "        self,\n",
        "        x: torch.LongTensor,\n",
        "        segment_label: torch.LongTensor,\n",
        "    ) -> Tuple[torch.Tensor, torch.Tensor]:\n",
        "        x = self._encoder(x, segment_label)\n",
        "        return self._next_sentence(x), self._mask_lm(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "class BERTTrainer:\n",
        "    def __init__(\n",
        "        self, \n",
        "        model: BERTLM, \n",
        "        train_dataloader: DataLoader, \n",
        "        test_dataloader: Optional[DataLoader] = None, \n",
        "        lr: float = 1e-4,\n",
        "        weight_decay: float = 0.01,\n",
        "        betas: Tuple[float, float] = (0.9, 0.999),\n",
        "        warmup_steps: int = 10000,\n",
        "        log_freq: int = 10,\n",
        "        device: str = 'cuda'\n",
        "    ) -> None:\n",
        "        self.device = device\n",
        "        self.model = model\n",
        "        self.train_data = train_dataloader\n",
        "        self.test_data = test_dataloader\n",
        "\n",
        "        self.optim = Adam(\n",
        "            self.model.parameters(),\n",
        "            lr=lr,\n",
        "            betas=betas,\n",
        "            weight_decay=weight_decay,\n",
        "        )\n",
        "        self.optim_schedule = ScheduledOptim(\n",
        "            optimizer=self.optim,\n",
        "            embedding_size=self.model._encoder.embedding_size,\n",
        "            n_warmup_steps=warmup_steps,\n",
        "        )\n",
        "\n",
        "        self.criterion = nn.NLLLoss(ignore_index=0)\n",
        "        self.log_freq = log_freq\n",
        "        print(\"Total Parameters:\", sum([p.nelement() for p in self.model.parameters()]))\n",
        "    \n",
        "    def train(self, epoch: int) -> None:\n",
        "        self.iteration(epoch, self.train_data)\n",
        "\n",
        "    def test(self, epoch: int) -> None:\n",
        "        self.iteration(epoch, self.test_data, train=False)\n",
        "\n",
        "    def iteration(self, epoch: int, data_loader: DataLoader, train: bool = True) -> None:\n",
        "        avg_loss = 0.0\n",
        "        total_correct = 0\n",
        "        total_element = 0\n",
        "        \n",
        "        mode = \"train\" if train else \"test\"\n",
        "\n",
        "        # progress bar\n",
        "        data_iter = tqdm(\n",
        "            enumerate(data_loader),\n",
        "            desc=\"EP_%s:%d\" % (mode, epoch),\n",
        "            total=len(data_loader),\n",
        "            bar_format=\"{l_bar}{r_bar}\"\n",
        "        )\n",
        "\n",
        "        for i, data in data_iter:\n",
        "\n",
        "            data: TrainingBatch\n",
        "            bert_input = data.input.to(self.device)\n",
        "            label = data.label.to(self.device)\n",
        "            segment_label = data.segment_label.to(self.device)\n",
        "            is_next = data.is_next.to(self.device).view(-1)\n",
        "\n",
        "            next_sent_output, mask_lm_output = self.model.forward(bert_input, segment_label)\n",
        "\n",
        "            next_loss = self.criterion(next_sent_output, is_next)\n",
        "            mask_loss = self.criterion(mask_lm_output.transpose(1, 2), label)\n",
        "\n",
        "            loss = next_loss + mask_loss\n",
        "\n",
        "            if train:\n",
        "                self.optim_schedule.zero_grad()\n",
        "                loss.backward()\n",
        "                self.optim_schedule.step_and_update_lr()\n",
        "\n",
        "            correct = next_sent_output.argmax(dim=-1).eq(is_next).sum().item()\n",
        "            avg_loss += loss.item()\n",
        "            total_correct += correct\n",
        "            total_element += is_next.nelement()\n",
        "\n",
        "            post_fix = {\n",
        "                \"epoch\": epoch,\n",
        "                \"iter\": i,\n",
        "                \"avg_loss\": avg_loss / (i + 1),\n",
        "                \"avg_acc\": total_correct / total_element * 100,\n",
        "                \"loss\": loss.item()\n",
        "            }\n",
        "\n",
        "            if i != 0 and i % self.log_freq == 0:\n",
        "                data_iter.write(str(post_fix))\n",
        "        print(\n",
        "            f\"EP{epoch}, {mode}: \\\n",
        "            avg_loss={avg_loss / len(data_iter)}, \\\n",
        "            total_acc={total_correct * 100.0 / total_element}\"\n",
        "        )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "VOCAB_SIZE = len(tokenizer.vocab)\n",
        "BATCH_SIZE = 128\n",
        "MAX_SEQ_LEN = 50\n",
        "N_LAYERS = 6\n",
        "EMBEDDING_SIZE = 64\n",
        "NUM_HEADS = 8\n",
        "HEAD_EMBEDDING_SIZE = EMBEDDING_SIZE // NUM_HEADS\n",
        "FCCN_HIDDEN_SIZE = EMBEDDING_SIZE * 4\n",
        "n_epoch = 10"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 155,
      "metadata": {},
      "outputs": [],
      "source": [
        "dataset = ChordDataset(\n",
        "    corpus=corpus,\n",
        "    fitted_tokenizer=tokenizer,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 160,
      "metadata": {},
      "outputs": [],
      "source": [
        "def collate(data: List[TrainingBatch]):   \n",
        "    inputs = torch.stack([batch.input for batch in data])\n",
        "    labels = torch.stack([batch.label for batch in data])\n",
        "    segment_labels = torch.stack([batch.segment_label for batch in data])\n",
        "    is_nexts = torch.stack([batch.is_next for batch in data])\n",
        "    return TrainingBatch(\n",
        "        input=torch.LongTensor(inputs),\n",
        "        label=torch.LongTensor(labels),\n",
        "        segment_label=torch.LongTensor(segment_labels),\n",
        "        is_next=torch.LongTensor(is_nexts),\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 161,
      "metadata": {},
      "outputs": [],
      "source": [
        "dataloader = DataLoader(\n",
        "    dataset=dataset,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    shuffle=True,\n",
        "    collate_fn=collate\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 162,
      "metadata": {},
      "outputs": [],
      "source": [
        "batch = next(iter(dataloader))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 163,
      "metadata": {},
      "outputs": [],
      "source": [
        "encoder = Encoder(\n",
        "    vocab_size=VOCAB_SIZE,\n",
        "    n_layers=N_LAYERS,\n",
        "    embedding_size=EMBEDDING_SIZE,\n",
        "    num_heads=NUM_HEADS,\n",
        "    head_embedding_size=HEAD_EMBEDDING_SIZE,\n",
        "    fcnn_hidden_size=FCCN_HIDDEN_SIZE,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 164,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total Parameters: 454783\n"
          ]
        }
      ],
      "source": [
        "bert_model = BERTLM(\n",
        "    encoder=encoder\n",
        ")\n",
        "device = \"cuda:0\"\n",
        "bert_trainer = BERTTrainer(\n",
        "    model=bert_model,\n",
        "    train_dataloader=dataloader,\n",
        "    device=device,\n",
        "    log_freq=200,\n",
        "    warmup_steps=1000,\n",
        "    lr=0.005,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 165,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 165,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "torch.cuda.is_available() "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Обучение"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 166,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "EP_train:0:   0%|| 0/1757 [00:00<?, ?it/s]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "EP_train:0:  11%|| 201/1757 [05:23<37:07,  1.43s/it]  "
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'epoch': 0, 'iter': 200, 'avg_loss': 4.583915023661372, 'avg_acc': 49.906716417910445, 'loss': 2.8390960693359375}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "EP_train:0:  23%|| 401/1757 [10:47<35:12,  1.56s/it]  "
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'epoch': 0, 'iter': 400, 'avg_loss': 3.635679988195177, 'avg_acc': 49.73503740648379, 'loss': 2.6608200073242188}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "EP_train:0:  34%|| 601/1757 [16:05<27:04,  1.41s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'epoch': 0, 'iter': 600, 'avg_loss': 3.2840149747750127, 'avg_acc': 49.762115224625624, 'loss': 2.6582040786743164}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "EP_train:0:  46%|| 801/1757 [21:15<22:49,  1.43s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'epoch': 0, 'iter': 800, 'avg_loss': 3.0971017681555204, 'avg_acc': 49.92489856429464, 'loss': 2.5018794536590576}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "EP_train:0:  57%|| 1001/1757 [26:29<18:15,  1.45s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'epoch': 0, 'iter': 1000, 'avg_loss': 2.980887124350259, 'avg_acc': 49.862637362637365, 'loss': 2.5605549812316895}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "EP_train:0:  68%|| 1201/1757 [31:39<14:00,  1.51s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'epoch': 0, 'iter': 1200, 'avg_loss': 2.900857978419003, 'avg_acc': 49.834773105745214, 'loss': 2.3839354515075684}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "EP_train:0:  80%|| 1401/1757 [36:49<09:34,  1.61s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'epoch': 0, 'iter': 1400, 'avg_loss': 2.8396837966600375, 'avg_acc': 49.878992683797286, 'loss': 2.479987382888794}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "EP_train:0:  91%|| 1601/1757 [41:53<03:24,  1.31s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'epoch': 0, 'iter': 1600, 'avg_loss': 2.7946713488970154, 'avg_acc': 49.887765459088065, 'loss': 2.398185968399048}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "EP_train:0: 100%|| 1757/1757 [45:56<00:00,  1.57s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "EP0, train:             avg_loss=2.7648969575906928,             total_acc=49.88990360448926\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "EP_train:1:  11%|| 201/1757 [05:18<36:41,  1.41s/it]  "
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'epoch': 1, 'iter': 200, 'avg_loss': 2.4513491635298847, 'avg_acc': 50.310945273631845, 'loss': 2.5045316219329834}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "EP_train:1:  23%|| 401/1757 [10:33<33:07,  1.47s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'epoch': 1, 'iter': 400, 'avg_loss': 2.4540527913338526, 'avg_acc': 50.1909289276808, 'loss': 2.261896848678589}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "EP_train:1:  34%|| 601/1757 [15:48<27:59,  1.45s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'epoch': 1, 'iter': 600, 'avg_loss': 2.449858318747776, 'avg_acc': 50.16508943427621, 'loss': 2.4617042541503906}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "EP_train:1:  46%|| 801/1757 [21:11<22:54,  1.44s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'epoch': 1, 'iter': 800, 'avg_loss': 2.4470131031136386, 'avg_acc': 50.0897315855181, 'loss': 2.557003974914551}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "EP_train:1:  57%|| 1001/1757 [26:33<16:56,  1.34s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'epoch': 1, 'iter': 1000, 'avg_loss': 2.4460702440240882, 'avg_acc': 49.960196053946056, 'loss': 2.511751651763916}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "EP_train:1:  68%|| 1201/1757 [31:50<14:02,  1.52s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'epoch': 1, 'iter': 1200, 'avg_loss': 2.444172134804388, 'avg_acc': 49.90242506244796, 'loss': 2.534467935562134}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "EP_train:1:  80%|| 1401/1757 [37:31<09:26,  1.59s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'epoch': 1, 'iter': 1400, 'avg_loss': 2.4430144889962238, 'avg_acc': 49.92583422555318, 'loss': 2.453115224838257}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "EP_train:1:  91%|| 1601/1757 [43:00<03:50,  1.48s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'epoch': 1, 'iter': 1600, 'avg_loss': 2.4407094749043243, 'avg_acc': 49.96486570893192, 'loss': 2.328341484069824}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "EP_train:1: 100%|| 1757/1757 [47:19<00:00,  1.62s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "EP1, train:             avg_loss=2.4392070979236133,             total_acc=49.97041854423651\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "EP_train:2:  11%|| 201/1757 [05:38<41:07,  1.59s/it]  "
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'epoch': 2, 'iter': 200, 'avg_loss': 2.4317682085938714, 'avg_acc': 50.3847947761194, 'loss': 2.4985995292663574}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "EP_train:2:  23%|| 401/1757 [11:15<36:38,  1.62s/it]  "
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'epoch': 2, 'iter': 400, 'avg_loss': 2.4274992235283603, 'avg_acc': 50.30782418952619, 'loss': 2.4928088188171387}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "EP_train:2:  34%|| 601/1757 [17:04<38:23,  1.99s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'epoch': 2, 'iter': 600, 'avg_loss': 2.4271739762952045, 'avg_acc': 50.1169925124792, 'loss': 2.346231698989868}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "EP_train:2:  46%|| 801/1757 [22:42<22:56,  1.44s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'epoch': 2, 'iter': 800, 'avg_loss': 2.428359199254849, 'avg_acc': 50.10631242197253, 'loss': 2.3193583488464355}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "EP_train:2:  57%|| 1001/1757 [28:19<19:49,  1.57s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'epoch': 2, 'iter': 1000, 'avg_loss': 2.4268581040732036, 'avg_acc': 50.0975586913087, 'loss': 2.447850465774536}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "EP_train:2:  68%|| 1201/1757 [33:45<14:15,  1.54s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'epoch': 2, 'iter': 1200, 'avg_loss': 2.426380247994327, 'avg_acc': 50.134653413821816, 'loss': 2.4470109939575195}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "EP_train:2:  80%|| 1401/1757 [39:06<09:17,  1.56s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'epoch': 2, 'iter': 1400, 'avg_loss': 2.4260179839927245, 'avg_acc': 50.105951106352606, 'loss': 2.3856284618377686}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "EP_train:2:  91%|| 1601/1757 [44:25<04:29,  1.73s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'epoch': 2, 'iter': 1600, 'avg_loss': 2.4267344503087003, 'avg_acc': 50.03903810118676, 'loss': 2.5323798656463623}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "EP_train:2: 100%|| 1757/1757 [48:33<00:00,  1.66s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "EP2, train:             avg_loss=2.4265949390934622,             total_acc=50.02958145576349\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "EP_train:3:  11%|| 201/1757 [05:29<39:35,  1.53s/it]  "
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'epoch': 3, 'iter': 200, 'avg_loss': 2.4150026947704712, 'avg_acc': 49.76679104477612, 'loss': 2.628065347671509}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "EP_train:3:  23%|| 401/1757 [10:48<35:39,  1.58s/it]  "
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'epoch': 3, 'iter': 400, 'avg_loss': 2.4174418033209824, 'avg_acc': 49.563591022443894, 'loss': 2.429598331451416}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "EP_train:3:  34%|| 601/1757 [15:58<27:00,  1.40s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'epoch': 3, 'iter': 600, 'avg_loss': 2.418319446671624, 'avg_acc': 49.57752703826955, 'loss': 2.4006240367889404}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "EP_train:3:  46%|| 801/1757 [21:08<23:23,  1.47s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'epoch': 3, 'iter': 800, 'avg_loss': 2.4197262747308588, 'avg_acc': 49.56109550561798, 'loss': 2.449817657470703}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "EP_train:3:  57%|| 1001/1757 [26:26<18:22,  1.46s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'epoch': 3, 'iter': 1000, 'avg_loss': 2.418215110466316, 'avg_acc': 49.71903096903097, 'loss': 2.4587457180023193}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "EP_train:3:  68%|| 1201/1757 [31:37<20:47,  2.24s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'epoch': 3, 'iter': 1200, 'avg_loss': 2.4184060595017685, 'avg_acc': 49.76451915070774, 'loss': 2.367908000946045}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "EP_train:3:  80%|| 1401/1757 [37:02<11:15,  1.90s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'epoch': 3, 'iter': 1400, 'avg_loss': 2.418870943261418, 'avg_acc': 49.70556745182012, 'loss': 2.498136281967163}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "EP_train:3:  91%|| 1601/1757 [42:20<03:49,  1.47s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'epoch': 3, 'iter': 1600, 'avg_loss': 2.4194897180196273, 'avg_acc': 49.78431449094316, 'loss': 2.3225836753845215}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "EP_train:3: 100%|| 1757/1757 [46:22<00:00,  1.58s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "EP3, train:             avg_loss=2.4196073837964183,             total_acc=49.7915953078918\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "EP_train:4:  11%|| 201/1757 [05:20<37:23,  1.44s/it]  "
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'epoch': 4, 'iter': 200, 'avg_loss': 2.422714774288348, 'avg_acc': 50.108830845771145, 'loss': 2.376873016357422}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "EP_train:4:  23%|| 401/1757 [10:49<45:13,  2.00s/it]  "
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'epoch': 4, 'iter': 400, 'avg_loss': 2.4157274470959518, 'avg_acc': 50.15001558603491, 'loss': 2.4925031661987305}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "EP_train:4:  34%|| 601/1757 [16:16<28:16,  1.47s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'epoch': 4, 'iter': 600, 'avg_loss': 2.4135962369636372, 'avg_acc': 50.02079866888519, 'loss': 2.510922908782959}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "EP_train:4:  46%|| 801/1757 [21:39<30:37,  1.92s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'epoch': 4, 'iter': 800, 'avg_loss': 2.4140640742769848, 'avg_acc': 50.12386860174781, 'loss': 2.4050257205963135}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "EP_train:4:  57%|| 1001/1757 [27:05<20:18,  1.61s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'epoch': 4, 'iter': 1000, 'avg_loss': 2.4154752865656985, 'avg_acc': 50.24038461538461, 'loss': 2.346954345703125}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "EP_train:4:  68%|| 1201/1757 [32:29<14:03,  1.52s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'epoch': 4, 'iter': 1200, 'avg_loss': 2.4151299496078176, 'avg_acc': 50.26410283097419, 'loss': 2.4232616424560547}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "EP_train:4:  80%|| 1401/1757 [37:54<08:51,  1.49s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'epoch': 4, 'iter': 1400, 'avg_loss': 2.4159295722299774, 'avg_acc': 50.2018647394718, 'loss': 2.435267925262451}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "EP_train:4:  91%|| 1601/1757 [43:28<04:02,  1.56s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'epoch': 4, 'iter': 1600, 'avg_loss': 2.4158846599321526, 'avg_acc': 50.2108057464085, 'loss': 2.353776454925537}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "EP_train:4: 100%|| 1757/1757 [47:47<00:00,  1.63s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "EP4, train:             avg_loss=2.415271248407641,             total_acc=50.23509472738353\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "EP_train:5:  11%|| 201/1757 [05:27<38:28,  1.48s/it]  "
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'epoch': 5, 'iter': 200, 'avg_loss': 2.4205935475838123, 'avg_acc': 49.261504975124375, 'loss': 2.391791820526123}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "EP_train:5:  23%|| 401/1757 [10:43<34:19,  1.52s/it]  "
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'epoch': 5, 'iter': 400, 'avg_loss': 2.421555832437149, 'avg_acc': 49.69996882793018, 'loss': 2.3811299800872803}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "EP_train:5:  34%|| 601/1757 [16:04<30:58,  1.61s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'epoch': 5, 'iter': 600, 'avg_loss': 2.4164815266398145, 'avg_acc': 49.98700083194675, 'loss': 2.4824087619781494}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "EP_train:5:  46%|| 801/1757 [21:25<24:19,  1.53s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'epoch': 5, 'iter': 800, 'avg_loss': 2.4162919467754578, 'avg_acc': 49.872230024968786, 'loss': 2.469680070877075}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "EP_train:5:  57%|| 1001/1757 [26:53<22:48,  1.81s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'epoch': 5, 'iter': 1000, 'avg_loss': 2.4162168276536238, 'avg_acc': 49.72527472527473, 'loss': 2.3064308166503906}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "EP_train:5:  68%|| 1201/1757 [32:16<14:12,  1.53s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'epoch': 5, 'iter': 1200, 'avg_loss': 2.416566780862165, 'avg_acc': 49.71378018318068, 'loss': 2.3835482597351074}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "EP_train:5:  80%|| 1401/1757 [37:37<08:42,  1.47s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'epoch': 5, 'iter': 1400, 'avg_loss': 2.4157460430194275, 'avg_acc': 49.79869289793005, 'loss': 2.4613330364227295}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "EP_train:5:  91%|| 1601/1757 [42:58<03:53,  1.50s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'epoch': 5, 'iter': 1600, 'avg_loss': 2.415535185353448, 'avg_acc': 49.788706277326675, 'loss': 2.510542154312134}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "EP_train:5: 100%|| 1757/1757 [47:09<00:00,  1.61s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "EP5, train:             avg_loss=2.4149234992370867,             total_acc=49.827182021592236\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "EP_train:6:  11%|| 201/1757 [05:27<1:01:53,  2.39s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'epoch': 6, 'iter': 200, 'avg_loss': 2.4164548003258397, 'avg_acc': 49.665733830845774, 'loss': 2.4156079292297363}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "EP_train:6:  23%|| 401/1757 [10:56<34:54,  1.54s/it]  "
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'epoch': 6, 'iter': 400, 'avg_loss': 2.4162255736657805, 'avg_acc': 49.76426122194514, 'loss': 2.46608829498291}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "EP_train:6:  34%|| 601/1757 [16:23<35:40,  1.85s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'epoch': 6, 'iter': 600, 'avg_loss': 2.414082328015675, 'avg_acc': 49.86870840266223, 'loss': 2.404184103012085}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "EP_train:6:  46%|| 801/1757 [21:47<23:36,  1.48s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'epoch': 6, 'iter': 800, 'avg_loss': 2.4112733898686707, 'avg_acc': 50.10631242197253, 'loss': 2.325376510620117}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "EP_train:6:  57%|| 1001/1757 [27:16<19:23,  1.54s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'epoch': 6, 'iter': 1000, 'avg_loss': 2.410376271763286, 'avg_acc': 50.01170704295704, 'loss': 2.4317941665649414}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "EP_train:6:  68%|| 1201/1757 [32:45<14:26,  1.56s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'epoch': 6, 'iter': 1200, 'avg_loss': 2.41138362249268, 'avg_acc': 49.95966902581183, 'loss': 2.383100986480713}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "EP_train:6:  80%|| 1401/1757 [38:07<08:48,  1.48s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'epoch': 6, 'iter': 1400, 'avg_loss': 2.41051588817463, 'avg_acc': 49.95538900785154, 'loss': 2.441837787628174}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "EP_train:6:  91%|| 1601/1757 [43:39<04:15,  1.64s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'epoch': 6, 'iter': 1600, 'avg_loss': 2.4113989537541083, 'avg_acc': 49.932171299188006, 'loss': 2.332197427749634}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "EP_train:6: 100%|| 1757/1757 [47:56<00:00,  1.64s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "EP6, train:             avg_loss=2.411682005151131,             total_acc=49.96863920855149\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "EP_train:7:  11%|| 201/1757 [05:30<38:11,  1.47s/it]  "
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'epoch': 7, 'iter': 200, 'avg_loss': 2.3979690691724938, 'avg_acc': 49.59577114427861, 'loss': 2.3971776962280273}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "EP_train:7:  23%|| 401/1757 [10:56<33:38,  1.49s/it]  "
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'epoch': 7, 'iter': 400, 'avg_loss': 2.4045810354618062, 'avg_acc': 49.78374376558604, 'loss': 2.4799129962921143}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "EP_train:7:  34%|| 601/1757 [16:24<34:01,  1.77s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'epoch': 7, 'iter': 600, 'avg_loss': 2.4059662315095722, 'avg_acc': 49.91030574043261, 'loss': 2.300373077392578}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "EP_train:7:  46%|| 801/1757 [21:51<25:44,  1.62s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'epoch': 7, 'iter': 800, 'avg_loss': 2.4079008176829784, 'avg_acc': 49.92977528089887, 'loss': 2.3746490478515625}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "EP_train:7:  57%|| 1001/1757 [27:19<20:47,  1.65s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'epoch': 7, 'iter': 1000, 'avg_loss': 2.4069193655198866, 'avg_acc': 50.050730519480524, 'loss': 2.492142677307129}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "EP_train:7:  68%|| 1201/1757 [32:48<14:31,  1.57s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'epoch': 7, 'iter': 1200, 'avg_loss': 2.406442662857653, 'avg_acc': 50.08131244796004, 'loss': 2.28385853767395}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "EP_train:7:  80%|| 1401/1757 [38:17<09:29,  1.60s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'epoch': 7, 'iter': 1400, 'avg_loss': 2.407244948129157, 'avg_acc': 50.012268022840836, 'loss': 2.5108680725097656}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "EP_train:7:  91%|| 1601/1757 [44:01<04:35,  1.76s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'epoch': 7, 'iter': 1600, 'avg_loss': 2.4072468356740693, 'avg_acc': 50.04586976889445, 'loss': 2.3663885593414307}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "EP_train:7: 100%|| 1757/1757 [48:19<00:00,  1.65s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "EP7, train:             avg_loss=2.407120781862132,             total_acc=50.046040310849946\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "EP_train:8:  11%|| 201/1757 [05:30<40:56,  1.58s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'epoch': 8, 'iter': 200, 'avg_loss': 2.3997126254276258, 'avg_acc': 50.221548507462686, 'loss': 2.3286755084991455}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "EP_train:8:  23%|| 401/1757 [11:27<36:53,  1.63s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'epoch': 8, 'iter': 400, 'avg_loss': 2.402316837834004, 'avg_acc': 50.12663653366584, 'loss': 2.472522258758545}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "EP_train:8:  34%|| 601/1757 [17:03<30:24,  1.58s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'epoch': 8, 'iter': 600, 'avg_loss': 2.404788430240904, 'avg_acc': 50.00779950083195, 'loss': 2.44401216506958}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "EP_train:8:  46%|| 801/1757 [22:36<30:04,  1.89s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'epoch': 8, 'iter': 800, 'avg_loss': 2.406702218728417, 'avg_acc': 50.06242197253433, 'loss': 2.523512125015259}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "EP_train:8:  57%|| 1001/1757 [28:13<20:16,  1.61s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'epoch': 8, 'iter': 1000, 'avg_loss': 2.406048832358895, 'avg_acc': 50.07414460539461, 'loss': 2.323251962661743}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "EP_train:8:  68%|| 1201/1757 [33:40<15:09,  1.64s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'epoch': 8, 'iter': 1200, 'avg_loss': 2.407300380743314, 'avg_acc': 50.12164342214821, 'loss': 2.3453943729400635}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "EP_train:8:  80%|| 1401/1757 [39:16<10:55,  1.84s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'epoch': 8, 'iter': 1400, 'avg_loss': 2.4068508280931753, 'avg_acc': 50.09647127052106, 'loss': 2.458913803100586}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "EP_train:8:  91%|| 1601/1757 [44:46<03:57,  1.52s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'epoch': 8, 'iter': 1600, 'avg_loss': 2.4068189946507603, 'avg_acc': 50.07807620237351, 'loss': 2.4273414611816406}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "EP_train:8: 100%|| 1757/1757 [49:00<00:00,  1.67s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "EP8, train:             avg_loss=2.4068693675028716,             total_acc=50.122106911384634\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "EP_train:9:  11%|| 201/1757 [05:33<50:47,  1.96s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'epoch': 9, 'iter': 200, 'avg_loss': 2.402234783220054, 'avg_acc': 50.36536069651741, 'loss': 2.369131565093994}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "EP_train:9:  23%|| 401/1757 [11:12<37:34,  1.66s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'epoch': 9, 'iter': 400, 'avg_loss': 2.406831335248495, 'avg_acc': 50.20067019950125, 'loss': 2.4412736892700195}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "EP_train:9:  34%|| 601/1757 [16:40<31:59,  1.66s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'epoch': 9, 'iter': 600, 'avg_loss': 2.4073949959036116, 'avg_acc': 50.12349209650583, 'loss': 2.363548755645752}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "EP_train:9:  46%|| 801/1757 [22:19<27:33,  1.73s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'epoch': 9, 'iter': 800, 'avg_loss': 2.4076826384897982, 'avg_acc': 50.11606585518103, 'loss': 2.4103188514709473}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "EP_train:9:  57%|| 1001/1757 [27:49<19:15,  1.53s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'epoch': 9, 'iter': 1000, 'avg_loss': 2.4092423318030236, 'avg_acc': 50.164679070929076, 'loss': 2.357564926147461}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "EP_train:9:  68%|| 1201/1757 [33:15<15:10,  1.64s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'epoch': 9, 'iter': 1200, 'avg_loss': 2.4082632017175323, 'avg_acc': 50.13140091590341, 'loss': 2.438218116760254}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "EP_train:9:  80%|| 1401/1757 [38:48<10:17,  1.73s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'epoch': 9, 'iter': 1400, 'avg_loss': 2.407226068645099, 'avg_acc': 50.09814418272662, 'loss': 2.3929646015167236}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "EP_train:9:  91%|| 1601/1757 [44:11<03:57,  1.52s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'epoch': 9, 'iter': 1600, 'avg_loss': 2.4079777207097584, 'avg_acc': 50.04977357901311, 'loss': 2.4873321056365967}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "EP_train:9: 100%|| 1757/1757 [48:29<00:00,  1.66s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "EP9, train:             avg_loss=2.407972543566622,             total_acc=50.046929978692454\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "bert_model.to(device)\n",
        "bert_model.train()\n",
        "for epoch in range(n_epoch):\n",
        "    bert_trainer.train(epoch)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Сохраняем модель"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Модель сохранена в chord_bert_model.pth\n"
          ]
        }
      ],
      "source": [
        "def save_model(model, tokenizer, filepath):\n",
        "    \"\"\"Сохраняет модель и токенайзер\"\"\"\n",
        "    checkpoint = {\n",
        "        'model_state_dict': model.model.state_dict(),\n",
        "        'tokenizer_vocab': tokenizer.vocab,\n",
        "        'tokenizer_reverse_vocab': tokenizer.reverse_vocab,\n",
        "        'model_config': {\n",
        "            'vocab_size': model.model._encoder.embedding_size,\n",
        "            'embedding_size': model.model._encoder.embedding_size,\n",
        "        }\n",
        "    }\n",
        "    \n",
        "    torch.save(checkpoint, filepath)\n",
        "    print(f\"Модель сохранена в {filepath}\")\n",
        "\n",
        "save_model(bert_trainer, tokenizer, 'chord_bert_model.pth')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Отдельно еще сохраняем токенайзер"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Токенайзер сохранен в chord_tokenizer.pth\n",
            "Токенайзер загружен из chord_tokenizer.pth\n"
          ]
        }
      ],
      "source": [
        "def save_tokenizer(tokenizer, filepath):\n",
        "    \"\"\"Сохраняет словарь токенайзера\"\"\"\n",
        "    tokenizer_data = {\n",
        "        '_vocab': tokenizer.vocab,\n",
        "        'notes': tokenizer.notes,\n",
        "        'moods': tokenizer.moods,\n",
        "        'extensions': tokenizer.extensions,\n",
        "        'symbols': tokenizer.symbols,\n",
        "        'complex_chords': tokenizer.complex_chords\n",
        "    }\n",
        "    \n",
        "    torch.save(tokenizer_data, filepath)\n",
        "    print(f\"Токенайзер сохранен в {filepath}\")\n",
        "\n",
        "def load_tokenizer(filepath):\n",
        "    \"\"\"Загружает токенайзер из файла\"\"\"\n",
        "    tokenizer_data = torch.load(filepath)\n",
        "    \n",
        "\n",
        "    tokenizer = ChordTokenizer()\n",
        "\n",
        "    tokenizer._vocab = tokenizer_data['_vocab']\n",
        "    tokenizer.notes = tokenizer_data['notes']\n",
        "    tokenizer.moods = tokenizer_data['moods']\n",
        "    tokenizer.extensions = tokenizer_data['extensions']\n",
        "    tokenizer.symbols = tokenizer_data['symbols']\n",
        "    tokenizer.complex_chords = tokenizer_data['complex_chords']\n",
        "    \n",
        "    print(f\"Токенайзер загружен из {filepath}\")\n",
        "    return tokenizer\n",
        "\n",
        "save_tokenizer(tokenizer, 'chord_tokenizer.pth')\n",
        "loaded_tokenizer = load_tokenizer('chord_tokenizer.pth')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Переключаем модельку в режим эвала"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 177,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "BERTLM(\n",
              "  (_encoder): Encoder(\n",
              "    (_embeddings): BERTEmbedding(\n",
              "      (_embeddings): Embedding(1213, 64, padding_idx=0)\n",
              "      (_segment_embeddings): Embedding(3, 64, padding_idx=0)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (_positional_embeddings): RotaryPositionEmbedding()\n",
              "    (_layers): ModuleList(\n",
              "      (0-5): 6 x EncoderLayer(\n",
              "        (_mha): RoPEMultiHeadedAttention(\n",
              "          (_positional_embedding): RotaryPositionEmbedding()\n",
              "          (_Q): Linear(in_features=64, out_features=64, bias=True)\n",
              "          (_K): Linear(in_features=64, out_features=64, bias=True)\n",
              "          (_V): Linear(in_features=64, out_features=64, bias=True)\n",
              "          (_W_proj): Linear(in_features=64, out_features=64, bias=True)\n",
              "          (_dropout): Dropout(p=0.1, inplace=False)\n",
              "          (_layernorm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
              "        )\n",
              "        (_fcnn): FCNNBlock(\n",
              "          (_linear1): Linear(in_features=64, out_features=256, bias=False)\n",
              "          (_linear2): Linear(in_features=256, out_features=64, bias=False)\n",
              "          (_activation): GELU(approximate='none')\n",
              "          (_layernorm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
              "          (_dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (_next_sentence): NextSentencePrediction(\n",
              "    (_linear): Linear(in_features=64, out_features=2, bias=True)\n",
              "    (_softmax): LogSoftmax(dim=-1)\n",
              "  )\n",
              "  (_mask_lm): MaskedLanguageModel(\n",
              "    (_linear): Linear(in_features=64, out_features=1213, bias=True)\n",
              "    (_softmax): LogSoftmax(dim=-1)\n",
              "  )\n",
              ")"
            ]
          },
          "execution_count": 177,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "bert_model.eval()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Пример предикта"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Предсказанный аккорд: C\n",
            "Предсказанный аккорд: G\n",
            "Предсказанный аккорд: C\n",
            "Предсказанный аккорд: G\n",
            "Предсказанный аккорд: G\n",
            "Предсказанный аккорд: G\n",
            "Предсказанный аккорд: G\n",
            "Предсказанный аккорд: G\n",
            "Предсказанный аккорд: G\n",
            "Предсказанный аккорд: G\n",
            "Предсказанный аккорд: G\n",
            "Предсказанный аккорд: G\n",
            "Предсказанный аккорд: G\n",
            "Предсказанный аккорд: C\n",
            "Предсказанный аккорд: G\n",
            "Предсказанный аккорд: G\n",
            "Предсказанный аккорд: C\n",
            "Предсказанный аккорд: C\n",
            "Предсказанный аккорд: G\n",
            "Предсказанный аккорд: C\n",
            "Предсказанный аккорд: G\n"
          ]
        }
      ],
      "source": [
        "def predict_masked_chord(model, tokenizer, chord_sequence):\n",
        "    \"\"\"\n",
        "    Предсказывает аккорд на месте знака вопроса в последовательности\n",
        "    Пример: [\"A\", \"B\", \"?\", \"B\", \"D\"] -> предсказывает аккорд вместо '?'\n",
        "    \"\"\"\n",
        "    print(f'Input {chord_sequence}')\n",
        "    chord_sequence = chord_sequence.split()\n",
        "    masked_sequence = [chord if chord != '?' else tokenizer._mask_token for chord in chord_sequence]\n",
        "    if tokenizer._mask_token not in masked_sequence:\n",
        "        masked_sequence.append(tokenizer._mask_token)\n",
        "\n",
        "    input_ids = tokenizer.tokenize_ids(masked_sequence)\n",
        "    input_ids = [i[1] for i in input_ids]\n",
        "\n",
        "\n",
        "    inputs = torch.tensor([input_ids])\n",
        "\n",
        "\n",
        "    mask_index = input_ids.index(tokenizer.mask_token_id)\n",
        "    segment_label = torch.zeros_like(inputs)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        outputs = model(inputs, segment_label)\n",
        "        predictions = outputs.logits if hasattr(outputs, 'logits') else outputs\n",
        "\n",
        "\n",
        "    predicted_index = torch.argmax(predictions[1][0][mask_index]).item()\n",
        "    predicted_chord = tokenizer.vocab.get(predicted_index, tokenizer._unknown_token)\n",
        "    masked_sequence[mask_index] = predicted_chord\n",
        "    separator = \" \"\n",
        "    result = separator.join(masked_sequence)\n",
        "    print(f'Result {result}')\n",
        "    return predicted_chord\n",
        "\n",
        "\n",
        "seqs = [\n",
        "'? C D F B B F B B F B B F D F C D D C D F',\n",
        "'D ? D F B B F B B F B B F D F C D D C D F',\n",
        "'D C ? F B B F B B F B B F D F C D D C D F',\n",
        "'D C D ? B B F B B F B B F D F C D D C D F',\n",
        "'D C D F ? B F B B F B B F D F C D D C D F',\n",
        "'D C D F B ? F B B F B B F D F C D D C D F',\n",
        "'D C D F B B ? B B F B B F D F C D D C D F',\n",
        "'D C D F B B F ? B F B B F D F C D D C D F',\n",
        "'D C D F B B F B ? F B B F D F C D D C D F',\n",
        "'D C D F B B F B B ? B B F D F C D D C D F',\n",
        "'D C D F B B F B B F ? B F D F C D D C D F',\n",
        "'D C D F B B F B B F B ? F D F C D D C D F',\n",
        "'D C D F B B F B B F B B ? D F C D D C D F',\n",
        "'D C D F B B F B B F B B F ? F C D D C D F',\n",
        "'D C D F B B F B B F B B F D ? C D D C D F',\n",
        "'D C D F B B F B B F B B F D F ? D D C D F',\n",
        "'D C D F B B F B B F B B F D F C ? D C D F',\n",
        "'D C D F B B F B B F B B F D F C D ? C D F',\n",
        "'D C D F B B F B B F B B F D F C D D ? D F',\n",
        "'D C D F B B F B B F B B F D F C D D C ? F',\n",
        "'D C D F B B F B B F B B F D F C D D C D ?'\n",
        "]\n",
        "for sequence in seqs:\n",
        "    predicted = predict_masked_chord(bert_model, tokenizer, sequence)\n",
        "    print(f\"Предсказанный аккорд: {predicted}\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
