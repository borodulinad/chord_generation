{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4c4839d6",
   "metadata": {},
   "source": [
    "–í —ç—Ç–æ–º –Ω–æ—É—Ç–±—É–∫–µ –ø—Ä–µ–¥—Å—Ç–∞–≤–ª–µ–Ω –ø—Ä–∏–º–µ—Ä –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è, –∞ —Ç–∞–∫–∂–µ —Ä–∞–∑–≤–µ—Ä—Ç—ã–≤–∞–Ω–∏–µ —Å–µ—Ä–≤–∏—Å–∞ –ø–æ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –∞–∫–∫–æ—Ä–¥–æ–≤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ae0664ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import polars as pl\n",
    "import math\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import random\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.optim import Adam\n",
    "from tqdm import tqdm\n",
    "\n",
    "import re\n",
    "from typing import List, Dict, Any, Tuple, Optional, Mapping, Set, Self, NamedTuple, TypedDict\n",
    "from utils import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "818dfe68",
   "metadata": {},
   "source": [
    "### –ó–∞–≥—Ä—É–∂–∞–µ–º –º–æ–¥–µ–ª—å"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "95ba8fa0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "–¢–æ–∫–µ–Ω–∞–π–∑–µ—Ä –∑–∞–≥—Ä—É–∂–µ–Ω –∏–∑ chord_tokenizer.pth\n"
     ]
    }
   ],
   "source": [
    "def load_tokenizer(filepath):\n",
    "    \"\"\"–ó–∞–≥—Ä—É–∂–∞–µ—Ç —Ç–æ–∫–µ–Ω–∞–π–∑–µ—Ä –∏–∑ —Ñ–∞–π–ª–∞\"\"\"\n",
    "    tokenizer_data = torch.load(filepath)\n",
    "    \n",
    "    # –°–æ–∑–¥–∞–µ–º –Ω–æ–≤—ã–π —Ç–æ–∫–µ–Ω–∞–π–∑–µ—Ä\n",
    "    tokenizer = ChordTokenizer()\n",
    "    \n",
    "    # –í–æ—Å—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º —Å–æ—Å—Ç–æ—è–Ω–∏–µ\n",
    "    tokenizer._vocab = tokenizer_data['_vocab']\n",
    "    tokenizer.notes = tokenizer_data['notes']\n",
    "    tokenizer.moods = tokenizer_data['moods']\n",
    "    tokenizer.extensions = tokenizer_data['extensions']\n",
    "    tokenizer.symbols = tokenizer_data['symbols']\n",
    "    tokenizer.complex_chords = tokenizer_data['complex_chords']\n",
    "    \n",
    "    print(f\"–¢–æ–∫–µ–Ω–∞–π–∑–µ—Ä –∑–∞–≥—Ä—É–∂–µ–Ω –∏–∑ {filepath}\")\n",
    "    return tokenizer\n",
    "loaded_tokenizer = load_tokenizer('chord_tokenizer.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f9d66282",
   "metadata": {},
   "outputs": [],
   "source": [
    "VOCAB_SIZE = len(loaded_tokenizer.vocab)\n",
    "BATCH_SIZE = 128\n",
    "MAX_SEQ_LEN = 50\n",
    "N_LAYERS = 6\n",
    "EMBEDDING_SIZE = 64\n",
    "NUM_HEADS = 8\n",
    "HEAD_EMBEDDING_SIZE = EMBEDDING_SIZE // NUM_HEADS\n",
    "FCCN_HIDDEN_SIZE = EMBEDDING_SIZE * 4\n",
    "n_epoch = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "625610ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "–ú–æ–¥–µ–ª—å –∑–∞–≥—Ä—É–∂–µ–Ω–∞ –∏–∑ /root/chord/chord_bert_model.pth\n"
     ]
    }
   ],
   "source": [
    "def load_model(filepath, encoder_class, encoder_config):\n",
    "    \"\"\"–ó–∞–≥—Ä—É–∂–∞–µ—Ç –º–æ–¥–µ–ª—å –∏–∑ —Ñ–∞–π–ª–∞\"\"\"\n",
    "    checkpoint = torch.load(filepath, map_location='cpu')\n",
    "    \n",
    "    encoder = encoder_class(**encoder_config)\n",
    "    model = BERTLM(encoder)\n",
    "    \n",
    "    model.load_state_dict(checkpoint['model_state_dict'])\n",
    "    \n",
    "    print(f\"–ú–æ–¥–µ–ª—å –∑–∞–≥—Ä—É–∂–µ–Ω–∞ –∏–∑ {filepath}\")\n",
    "    \n",
    "    return model\n",
    "\n",
    "\n",
    "encoder_config = {\n",
    "    'vocab_size': VOCAB_SIZE,\n",
    "    'n_layers': N_LAYERS,\n",
    "    'embedding_size': EMBEDDING_SIZE,\n",
    "    'num_heads': NUM_HEADS,\n",
    "    'head_embedding_size': HEAD_EMBEDDING_SIZE,\n",
    "    'fcnn_hidden_size': FCCN_HIDDEN_SIZE,\n",
    "}\n",
    "\n",
    "loaded_model = load_model('/root/chord/chord_bert_model.pth', Encoder, encoder_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "db3726cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BERTLM(\n",
       "  (_encoder): Encoder(\n",
       "    (_embeddings): BERTEmbedding(\n",
       "      (_embeddings): Embedding(1213, 64, padding_idx=0)\n",
       "      (_segment_embeddings): Embedding(3, 64, padding_idx=0)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (_positional_embeddings): RotaryPositionEmbedding()\n",
       "    (_layers): ModuleList(\n",
       "      (0-5): 6 x EncoderLayer(\n",
       "        (_mha): RoPEMultiHeadedAttention(\n",
       "          (_positional_embedding): RotaryPositionEmbedding()\n",
       "          (_Q): Linear(in_features=64, out_features=64, bias=True)\n",
       "          (_K): Linear(in_features=64, out_features=64, bias=True)\n",
       "          (_V): Linear(in_features=64, out_features=64, bias=True)\n",
       "          (_W_proj): Linear(in_features=64, out_features=64, bias=True)\n",
       "          (_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (_layernorm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (_fcnn): FCNNBlock(\n",
       "          (_linear1): Linear(in_features=64, out_features=256, bias=False)\n",
       "          (_linear2): Linear(in_features=256, out_features=64, bias=False)\n",
       "          (_activation): GELU(approximate='none')\n",
       "          (_layernorm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "          (_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (_next_sentence): NextSentencePrediction(\n",
       "    (_linear): Linear(in_features=64, out_features=2, bias=True)\n",
       "    (_softmax): LogSoftmax(dim=-1)\n",
       "  )\n",
       "  (_mask_lm): MaskedLanguageModel(\n",
       "    (_linear): Linear(in_features=64, out_features=1213, bias=True)\n",
       "    (_softmax): LogSoftmax(dim=-1)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loaded_model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "efbd2442",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_masked_chord(model, tokenizer, chord_sequence):\n",
    "    \"\"\"\n",
    "    –ü—Ä–µ–¥—Å–∫–∞–∑—ã–≤–∞–µ—Ç –∞–∫–∫–æ—Ä–¥ –Ω–∞ –º–µ—Å—Ç–µ –∑–Ω–∞–∫–∞ –≤–æ–ø—Ä–æ—Å–∞ –≤ –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç–∏\n",
    "    –ü—Ä–∏–º–µ—Ä: [\"A\", \"B\", \"?\", \"B\", \"D\"] -> –ø—Ä–µ–¥—Å–∫–∞–∑—ã–≤–∞–µ—Ç –∞–∫–∫–æ—Ä–¥ –≤–º–µ—Å—Ç–æ '?'\n",
    "    \"\"\"\n",
    "\n",
    "    print(f'Input {chord_sequence}')\n",
    "    chord_sequence = chord_sequence.split()\n",
    "    masked_sequence = [chord if chord != '?' else tokenizer._mask_token for chord in chord_sequence]\n",
    "    if tokenizer._mask_token not in masked_sequence:\n",
    "        masked_sequence.append(tokenizer._mask_token)\n",
    "\n",
    "    input_ids = tokenizer.tokenize_ids(masked_sequence)\n",
    "    input_ids = [i[1] for i in input_ids]\n",
    "\n",
    "\n",
    "    inputs = torch.tensor([input_ids])\n",
    "\n",
    "    mask_index = input_ids.index(tokenizer.mask_token_id)\n",
    "    segment_label = torch.zeros_like(inputs)\n",
    "    # –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ\n",
    "    with torch.no_grad():\n",
    "        outputs = model(inputs, segment_label)\n",
    "        predictions = outputs.logits if hasattr(outputs, 'logits') else outputs\n",
    "\n",
    "    predicted_index = torch.argmax(predictions[1][0][mask_index]).item()\n",
    "    predicted_chord = tokenizer.vocab.get(predicted_index, tokenizer._unknown_token)\n",
    "    masked_sequence[mask_index] = predicted_chord\n",
    "    separator = \" \"\n",
    "    result = separator.join(masked_sequence)\n",
    "    print(f'Result {result}')\n",
    "    return predicted_chord, result, predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "52c5d627",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input D C D F B B F B B F B ? F D F C D D C D D F\n",
      "Result D C D F B B F B B F B G F D F C D D C D D F\n"
     ]
    }
   ],
   "source": [
    "predicted_chord, result, predictions = predict_masked_chord(loaded_model, loaded_tokenizer, 'D C D F B B F B B F B ? F D F C D D C D D F')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3227896",
   "metadata": {},
   "source": [
    "### –ü–æ–¥–Ω–∏–º–∞–µ–º gradio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c2881dfc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/venv/lib/python3.12/site-packages/gradio/interface.py:415: UserWarning: The `allow_flagging` parameter in `Interface` is deprecated. Use `flagging_mode` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7860\n",
      "* To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7860/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input D C D F B B F B B F B B F ? F C D D C D F\n",
      "Result D C D F B B F B B F B B F C F C D D C D F\n"
     ]
    }
   ],
   "source": [
    "import gradio as gr\n",
    "import numpy as np\n",
    "import io\n",
    "import wave\n",
    "import random\n",
    "\n",
    "\n",
    "# –°–∏–Ω—Ç–µ–∑ –≥–∏—Ç–∞—Ä–Ω–æ–≥–æ –∑–≤—É–∫–∞ \n",
    "SAMPLE_RATE = 22050\n",
    "\n",
    "NOTE_FREQS = {\n",
    "    'C': 261.6, 'C#': 277.2, 'Db': 277.2,\n",
    "    'D': 293.7, 'D#': 311.1, 'Eb': 311.1,\n",
    "    'E': 329.6, 'F': 349.2, 'F#': 370.0,\n",
    "    'Gb': 370.0, 'G': 392.0, 'G#': 415.3,\n",
    "    'Ab': 415.3, 'A': 440.0, 'A#': 466.2,\n",
    "    'Bb': 466.2, 'B': 493.9\n",
    "}\n",
    "\n",
    "INTERVALS = {\n",
    "    'maj': [0, 4, 7],\n",
    "    'min': [0, 3, 7],\n",
    "    'dim': [0, 3, 6],\n",
    "    'aug': [0, 4, 8],\n",
    "    '7': [0, 4, 7, 10],\n",
    "    'maj7': [0, 4, 7, 11],\n",
    "    'm7': [0, 3, 7, 10],\n",
    "    'sus2': [0, 2, 7],\n",
    "    'sus4': [0, 5, 7],\n",
    "    '5': [0, 7]\n",
    "}\n",
    "\n",
    "def parse_chord(chord):\n",
    "    chord = chord.strip()\n",
    "    root = ''\n",
    "    quality = ''\n",
    "    for note in sorted(NOTE_FREQS.keys(), key=lambda x: -len(x)):\n",
    "        if chord.startswith(note):\n",
    "            root = note\n",
    "            quality = chord[len(note):]\n",
    "            break\n",
    "    if quality == '':\n",
    "        quality = 'maj'\n",
    "    if quality in ['m', 'min']:\n",
    "        quality = 'min'\n",
    "    elif quality in ['maj', '']:\n",
    "        quality = 'maj'\n",
    "    if quality not in INTERVALS:\n",
    "        quality = 'maj'\n",
    "    return root, quality\n",
    "\n",
    "def chord_to_wave_guitar(chord, duration=1.1):\n",
    "    root, quality = parse_chord(chord)\n",
    "    base_freq = NOTE_FREQS.get(root, 261.6)\n",
    "    intervals = INTERVALS[quality]\n",
    "\n",
    "    t = np.linspace(0, duration, int(SAMPLE_RATE * duration), False)\n",
    "    wave_data = np.zeros_like(t)\n",
    "    for interval in intervals:\n",
    "        freq = base_freq * 2 ** (interval / 12)\n",
    "        envelope = np.exp(-3 * t)  # –≥–∏—Ç–∞—Ä–Ω–æ–µ –∑–∞—Ç—É—Ö–∞–Ω–∏–µ\n",
    "        wave_data += 0.3 * np.sin(2 * np.pi * freq * t) * envelope\n",
    "\n",
    "    wave_data = wave_data / np.max(np.abs(wave_data))\n",
    "    pcm = (wave_data * 32767).astype(np.int16)\n",
    "\n",
    "    buf = io.BytesIO()\n",
    "    with wave.open(buf, \"wb\") as wf:\n",
    "        wf.setnchannels(1)\n",
    "        wf.setsampwidth(2)\n",
    "        wf.setframerate(SAMPLE_RATE)\n",
    "        wf.writeframes(pcm.tobytes())\n",
    "    return buf.getvalue()\n",
    "\n",
    "def sequence_to_audio(chords: str):\n",
    "    chunks = [chord_to_wave_guitar(ch) for ch in chords.split()]\n",
    "    full = io.BytesIO()\n",
    "    with wave.open(full, \"wb\") as wf:\n",
    "        wf.setnchannels(1)\n",
    "        wf.setsampwidth(2)\n",
    "        wf.setframerate(SAMPLE_RATE)\n",
    "        for w in chunks:\n",
    "            wf.writeframes(wave.open(io.BytesIO(w)).readframes(99999999))\n",
    "    return full.getvalue()\n",
    "\n",
    "\n",
    "def predict_chords(user_input):\n",
    "    result_chords = predict_masked_chord(loaded_model, loaded_tokenizer, user_input)[1]\n",
    "    audio_bytes = sequence_to_audio(result_chords)\n",
    "    return result_chords, (SAMPLE_RATE, np.frombuffer(audio_bytes, dtype=np.int16))\n",
    "\n",
    "iface = gr.Interface(\n",
    "    fn=predict_chords,\n",
    "    inputs=[\n",
    "        gr.Textbox(label=\"–í–≤–µ–¥–∏—Ç–µ –∞–∫–∫–æ—Ä–¥—ã\", placeholder=\"Am ? Dm E\")\n",
    "    ],\n",
    "    outputs=[\n",
    "        gr.Textbox(label=\"–°–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –∞–∫–∫–æ—Ä–¥—ã\"),\n",
    "        gr.Audio(label=\"–ê—É–¥–∏–æ\", type=\"numpy\")\n",
    "    ],\n",
    "    title=\"üé∏ –ì–µ–Ω–µ—Ä–∞—Ç–æ—Ä –∞–∫–∫–æ—Ä–¥–æ–≤\", \n",
    "    allow_flagging='never'\n",
    ")\n",
    "\n",
    "iface.launch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a50ac58f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
