{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4c4839d6",
   "metadata": {},
   "source": [
    "–í —ç—Ç–æ–º –Ω–æ—É—Ç–±—É–∫–µ –ø—Ä–µ–¥—Å—Ç–∞–≤–ª–µ–Ω –ø—Ä–∏–º–µ—Ä –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è, –∞ —Ç–∞–∫–∂–µ —Ä–∞–∑–≤–µ—Ä—Ç—ã–≤–∞–Ω–∏–µ —Å–µ—Ä–≤–∏—Å–∞ –ø–æ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –∞–∫–∫–æ—Ä–¥–æ–≤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ae0664ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import polars as pl\n",
    "import math\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import random\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.optim import Adam\n",
    "from tqdm import tqdm\n",
    "\n",
    "import re\n",
    "from typing import List, Dict, Any, Tuple, Optional, Mapping, Set, Self, NamedTuple, TypedDict\n",
    "from utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0ca70a97",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ChordTokenizer:\n",
    "    def __init__(self):\n",
    "        self._padding_token = \"[PAD]\"\n",
    "        self._unknown_token = \"[UNK]\"\n",
    "        self._cls_token = \"[CLS]\"\n",
    "        self._sep_token = \"[SEP]\"\n",
    "        self._mask_token = \"[MASK]\"\n",
    "        \n",
    "        # Special tokens IDs\n",
    "        self._padding_id = 0\n",
    "        self._cls_id = 1\n",
    "        self._sep_id = 2\n",
    "        self._mask_token_id = 3\n",
    "        self._unknown_token_id = 4\n",
    "        \n",
    "        # –ú—É–∑—ã–∫–∞–ª—å–Ω—ã–µ —ç–ª–µ–º–µ–Ω—Ç—ã\n",
    "        self.notes = ['C', 'C#', 'D', 'D#', 'E', 'F', 'F#', 'G', 'G#', 'A', 'A#', 'B']\n",
    "        self.moods = ['m', 'maj', 'min', 'aug', 'dim', 'sus2', 'sus4', 'sus']\n",
    "        self.extensions = [\n",
    "            '5', '6', '7', '9', '11', '13', \n",
    "            'add9', 'add11', 'add13'\n",
    "        ]\n",
    "        self.symbols = ['/', 'b', '#', '(', ')', ' ']\n",
    "        \n",
    "        # –°–ª–æ–∂–Ω—ã–µ –∞–∫–∫–æ—Ä–¥—ã –¥–ª—è –¥–æ–±–∞–≤–ª–µ–Ω–∏—è –≤ —Å–ª–æ–≤–∞—Ä—å\n",
    "        self.complex_chords = [\n",
    "            'A5(9)', 'Cadd9', 'Dsus4', 'Emadd9', 'G5(11)',\n",
    "            'Fmaj7', 'G9', 'Am11', 'C7(9)', 'Dsus2',\n",
    "            'Cmaj9', 'F#m7', 'Bbmaj7', 'E7sus4', 'Aadd9'\n",
    "        ]\n",
    "        \n",
    "        self._init_vocab()\n",
    "\n",
    "    @property\n",
    "    def vocab(self) -> Mapping[int, str]:\n",
    "        return self._vocab\n",
    "    \n",
    "    @property\n",
    "    def reverse_vocab(self) -> Mapping[str, int]:\n",
    "        return {token: idx for idx, token in self._vocab.items()}\n",
    "    \n",
    "    @property\n",
    "    def cls_id(self) -> int:\n",
    "        return self._cls_id\n",
    "    \n",
    "    @property\n",
    "    def mask_token_id(self) -> int:\n",
    "        return self._mask_token_id\n",
    "    \n",
    "    @property\n",
    "    def padding_id(self) -> int:\n",
    "        return self._padding_id\n",
    "    \n",
    "    @property\n",
    "    def sep_id(self) -> int:\n",
    "        return self._sep_id\n",
    "    \n",
    "    @property\n",
    "    def unknown_token_id(self) -> int:\n",
    "        return self._unknown_token_id\n",
    "\n",
    "    def _init_vocab(self) -> None:\n",
    "        \"\"\"–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è —Å–ª–æ–≤–∞—Ä—è —Å —Å–ø–µ—Ü–∏–∞–ª—å–Ω—ã–º–∏ —Ç–æ–∫–µ–Ω–∞–º–∏\"\"\"\n",
    "        self._vocab = {\n",
    "            self._padding_id: self._padding_token,\n",
    "            self._cls_id: self._cls_token,\n",
    "            self._sep_id: self._sep_token,\n",
    "            self._mask_token_id: self._mask_token,\n",
    "            self._unknown_token_id: self._unknown_token,\n",
    "        }\n",
    "    \n",
    "    def fit(self, corpus: List[str]) -> Self:\n",
    "        \"\"\"–°–æ–∑–¥–∞–Ω–∏–µ —Å–ª–æ–≤–∞—Ä—è –Ω–∞ –æ—Å–Ω–æ–≤–µ –∫–æ—Ä–ø—É—Å–∞\"\"\"\n",
    "        self._init_vocab()\n",
    "        \n",
    "        # –î–æ–±–∞–≤–ª—è–µ–º –±–∞–∑–æ–≤—ã–µ –º—É–∑—ã–∫–∞–ª—å–Ω—ã–µ —ç–ª–µ–º–µ–Ω—Ç—ã\n",
    "        all_elements = (self.notes + self.moods + self.extensions + \n",
    "                       self.symbols + self.complex_chords)\n",
    "        \n",
    "        for element in all_elements:\n",
    "            if element not in self._vocab.values():\n",
    "                self._vocab[len(self._vocab)] = element\n",
    "        \n",
    "        # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –∫–æ—Ä–ø—É—Å –¥–ª—è –∏–∑–≤–ª–µ—á–µ–Ω–∏—è –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã—Ö –∞–∫–∫–æ—Ä–¥–æ–≤\n",
    "        for text in corpus:\n",
    "            chords = text.split()\n",
    "            for chord in chords:\n",
    "                if chord not in self.reverse_vocab and chord not in self._vocab.values():\n",
    "                    self._vocab[len(self._vocab)] = chord\n",
    "        \n",
    "        return self\n",
    "    \n",
    "    def tokenize_text(self, text: str | List[str]) -> List[str] | List[List[str]]:\n",
    "        \"\"\"–¢–æ–∫–µ–Ω–∏–∑–∞—Ü–∏—è —Ç–µ–∫—Å—Ç–∞ –≤ —Å—Ç—Ä–æ–∫–æ–≤—ã–µ —Ç–æ–∫–µ–Ω—ã\"\"\"\n",
    "        if isinstance(text, str):\n",
    "            return self._tokenize_text(text)\n",
    "        assert isinstance(text, list), \"`text` should be str or List[str]\"\n",
    "        return [self._tokenize_text(chunk) for chunk in text]\n",
    " \n",
    "    def tokenize_ids(self, text: str | List[str]) -> List[int] | List[List[int]]:\n",
    "        \"\"\"–¢–æ–∫–µ–Ω–∏–∑–∞—Ü–∏—è —Ç–µ–∫—Å—Ç–∞ –≤ ID —Ç–æ–∫–µ–Ω–æ–≤\"\"\"\n",
    "        if isinstance(text, str):\n",
    "            return self._tokenize_ids(text)\n",
    "        assert isinstance(text, list), \"`text` should be str or List[str]\"\n",
    "        return [self._tokenize_ids(chunk) for chunk in text]\n",
    "    \n",
    "    def decode(self, tokens: List[int]) -> str:\n",
    "        \"\"\"–î–µ–∫–æ–¥–∏—Ä–æ–≤–∞–Ω–∏–µ ID —Ç–æ–∫–µ–Ω–æ–≤ –æ–±—Ä–∞—Ç–Ω–æ –≤ —Å—Ç—Ä–æ–∫—É\"\"\"\n",
    "        content = []\n",
    "        reverse_vocab = self.reverse_vocab\n",
    "        \n",
    "        for token_id in tokens:\n",
    "            if token_id in [self._padding_id, self._cls_id, self._sep_id, self._mask_token_id]:\n",
    "                continue\n",
    "            \n",
    "            token = self._vocab.get(token_id, self._unknown_token)\n",
    "            if token == self._unknown_token:\n",
    "                continue\n",
    "                \n",
    "            content.append(token)\n",
    "        \n",
    "        # –°–æ–±–∏—Ä–∞–µ–º –∞–∫–∫–æ—Ä–¥—ã –∏–∑ —Ç–æ–∫–µ–Ω–æ–≤\n",
    "        result = []\n",
    "        current_chord = []\n",
    "        \n",
    "        for token in content:\n",
    "            if token == ' ':\n",
    "                if current_chord:\n",
    "                    result.append(''.join(current_chord))\n",
    "                    current_chord = []\n",
    "            else:\n",
    "                current_chord.append(token)\n",
    "        \n",
    "        if current_chord:\n",
    "            result.append(''.join(current_chord))\n",
    "            \n",
    "        return ' '.join(result)\n",
    "\n",
    "    def _tokenize_text(self, text: str) -> List[str]:\n",
    "        \"\"\"–í–Ω—É—Ç—Ä–µ–Ω–Ω–∏–π –º–µ—Ç–æ–¥ –¥–ª—è —Ç–æ–∫–µ–Ω–∏–∑–∞—Ü–∏–∏ —Å—Ç—Ä–æ–∫–∏ –≤ —Ç–µ–∫—Å—Ç–æ–≤—ã–µ —Ç–æ–∫–µ–Ω—ã\"\"\"\n",
    "        tokens = [self._cls_token]\n",
    "        reverse_vocab = self.reverse_vocab\n",
    "        \n",
    "        chords = text.split()\n",
    "        \n",
    "        for i, chord in enumerate(chords):\n",
    "            # –ü—ã—Ç–∞–µ–º—Å—è –Ω–∞–π—Ç–∏ —Ü–µ–ª—ã–π –∞–∫–∫–æ—Ä–¥ –≤ —Å–ª–æ–≤–∞—Ä–µ\n",
    "            if chord in reverse_vocab:\n",
    "                tokens.append(chord)\n",
    "            else:\n",
    "                # –†–∞–∑–±–∏–≤–∞–µ–º –∞–∫–∫–æ—Ä–¥ –Ω–∞ —Å–æ—Å—Ç–∞–≤–ª—è—é—â–∏–µ\n",
    "                chord_parts = self._split_chord(chord)\n",
    "                for part in chord_parts:\n",
    "                    if part in reverse_vocab:\n",
    "                        tokens.append(part)\n",
    "                    else:\n",
    "                        tokens.append(self._unknown_token)\n",
    "            \n",
    "            # –î–æ–±–∞–≤–ª—è–µ–º –ø—Ä–æ–±–µ–ª –º–µ–∂–¥—É –∞–∫–∫–æ—Ä–¥–∞–º–∏ (–∫—Ä–æ–º–µ –ø–æ—Å–ª–µ–¥–Ω–µ–≥–æ)\n",
    "            if i < len(chords) - 1:\n",
    "                tokens.append(' ')\n",
    "        \n",
    "        tokens.append(self._sep_token)\n",
    "        return tokens\n",
    "    \n",
    "    def _tokenize_ids(self, text: str) -> List[int]:\n",
    "        \"\"\"–í–Ω—É—Ç—Ä–µ–Ω–Ω–∏–π –º–µ—Ç–æ–¥ –¥–ª—è —Ç–æ–∫–µ–Ω–∏–∑–∞—Ü–∏–∏ —Å—Ç—Ä–æ–∫–∏ –≤ ID —Ç–æ–∫–µ–Ω–æ–≤\"\"\"\n",
    "        text_tokens = self._tokenize_text(text)\n",
    "        reverse_vocab = self.reverse_vocab\n",
    "        return [reverse_vocab.get(token, self._unknown_token_id) for token in text_tokens]\n",
    "    \n",
    "    def _split_chord(self, chord: str) -> List[str]:\n",
    "        \"\"\"–†–∞–∑–±–∏–≤–∞–µ—Ç –∞–∫–∫–æ—Ä–¥ –Ω–∞ —Å–æ—Å—Ç–∞–≤–ª—è—é—â–∏–µ —ç–ª–µ–º–µ–Ω—Ç—ã\"\"\"\n",
    "        # –†–µ–≥—É–ª—è—Ä–Ω–æ–µ –≤—ã—Ä–∞–∂–µ–Ω–∏–µ –¥–ª—è —Ä–∞–∑–±–æ—Ä–∞ –∞–∫–∫–æ—Ä–¥–æ–≤\n",
    "        pattern = r'[A-G][#b]?|[a-z]+|\\d+|[\\/\\(\\)#b]'\n",
    "        parts = re.findall(pattern, chord)\n",
    "        return parts\n",
    "    \n",
    "    def __len__(self) -> int:\n",
    "        return len(self._vocab)\n",
    "\n",
    "    \n",
    "class ChordTokenizerHF:\n",
    "    def __init__(self, chord_tokenizer: ChordTokenizer):\n",
    "        self.chord_tokenizer = chord_tokenizer\n",
    "\n",
    "    def __call__(self, texts, padding=True, truncation=True, max_length=128, return_tensors=None):\n",
    "        if isinstance(texts, str):\n",
    "            texts = [texts]\n",
    "\n",
    "        input_ids = []\n",
    "        attention_masks = []\n",
    "\n",
    "        for text in texts:\n",
    "            token_ids = self.chord_tokenizer.tokenize_ids(text)\n",
    "\n",
    "            # –û–±—Ä–µ–∑–∞–µ–º –µ—Å–ª–∏ –Ω—É–∂–Ω–æ\n",
    "            if truncation and len(token_ids) > max_length:\n",
    "                token_ids = token_ids[:max_length]\n",
    "\n",
    "            attention_mask = [1] * len(token_ids)\n",
    "\n",
    "            # –î–æ–±–∞–≤–ª—è–µ–º –ø–∞–¥–¥–∏–Ω–≥ –µ—Å–ª–∏ –Ω—É–∂–Ω–æ\n",
    "            if padding:\n",
    "                padding_length = max_length - len(token_ids)\n",
    "                token_ids = token_ids + [self.chord_tokenizer.padding_id] * padding_length\n",
    "                attention_mask = attention_mask + [0] * padding_length\n",
    "\n",
    "            input_ids.append(token_ids)\n",
    "            attention_masks.append(attention_mask)\n",
    "\n",
    "        output = {\n",
    "            'input_ids': input_ids,\n",
    "            'attention_mask': attention_masks\n",
    "        }\n",
    "\n",
    "        if return_tensors == 'pt':\n",
    "            import torch\n",
    "            output['input_ids'] = torch.tensor(output['input_ids'])\n",
    "            output['attention_mask'] = torch.tensor(output['attention_mask'])\n",
    "\n",
    "        return output\n",
    "\n",
    "    def decode(self, token_ids: List[int]) -> str:\n",
    "        \"\"\"–î–µ–∫–æ–¥–∏—Ä–æ–≤–∞–Ω–∏–µ ID —Ç–æ–∫–µ–Ω–æ–≤ –æ–±—Ä–∞—Ç–Ω–æ –≤ —Å—Ç—Ä–æ–∫—É\"\"\"\n",
    "        return self.chord_tokenizer.decode(token_ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "818dfe68",
   "metadata": {},
   "source": [
    "### –ó–∞–≥—Ä—É–∂–∞–µ–º –º–æ–¥–µ–ª—å"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "95ba8fa0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "–¢–æ–∫–µ–Ω–∞–π–∑–µ—Ä –∑–∞–≥—Ä—É–∂–µ–Ω –∏–∑ chord_tokenizer.pth\n"
     ]
    }
   ],
   "source": [
    "def load_tokenizer(filepath):\n",
    "    \"\"\"–ó–∞–≥—Ä—É–∂–∞–µ—Ç —Ç–æ–∫–µ–Ω–∞–π–∑–µ—Ä –∏–∑ —Ñ–∞–π–ª–∞\"\"\"\n",
    "    tokenizer_data = torch.load(filepath)\n",
    "    \n",
    "    # –°–æ–∑–¥–∞–µ–º –Ω–æ–≤—ã–π —Ç–æ–∫–µ–Ω–∞–π–∑–µ—Ä\n",
    "    tokenizer = ChordTokenizer()\n",
    "    \n",
    "    # –í–æ—Å—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º —Å–æ—Å—Ç–æ—è–Ω–∏–µ\n",
    "    tokenizer._vocab = tokenizer_data['_vocab']\n",
    "    tokenizer.notes = tokenizer_data['notes']\n",
    "    tokenizer.moods = tokenizer_data['moods']\n",
    "    tokenizer.extensions = tokenizer_data['extensions']\n",
    "    tokenizer.symbols = tokenizer_data['symbols']\n",
    "    tokenizer.complex_chords = tokenizer_data['complex_chords']\n",
    "    \n",
    "    print(f\"–¢–æ–∫–µ–Ω–∞–π–∑–µ—Ä –∑–∞–≥—Ä—É–∂–µ–Ω –∏–∑ {filepath}\")\n",
    "    return tokenizer\n",
    "loaded_tokenizer = load_tokenizer('chord_tokenizer.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f9d66282",
   "metadata": {},
   "outputs": [],
   "source": [
    "VOCAB_SIZE = len(loaded_tokenizer.vocab)\n",
    "BATCH_SIZE = 128\n",
    "MAX_SEQ_LEN = 50\n",
    "N_LAYERS = 6\n",
    "EMBEDDING_SIZE = 64\n",
    "NUM_HEADS = 8\n",
    "HEAD_EMBEDDING_SIZE = EMBEDDING_SIZE // NUM_HEADS\n",
    "FCCN_HIDDEN_SIZE = EMBEDDING_SIZE * 4\n",
    "n_epoch = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "625610ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "–ú–æ–¥–µ–ª—å –∑–∞–≥—Ä—É–∂–µ–Ω–∞ –∏–∑ chord_bert_model.pth\n"
     ]
    }
   ],
   "source": [
    "def load_model(filepath, encoder_class, encoder_config):\n",
    "    \"\"\"–ó–∞–≥—Ä—É–∂–∞–µ—Ç –º–æ–¥–µ–ª—å –∏–∑ —Ñ–∞–π–ª–∞\"\"\"\n",
    "    checkpoint = torch.load(filepath, map_location='cpu')\n",
    "    \n",
    "    encoder = encoder_class(**encoder_config)\n",
    "    model = BERTLM(encoder)\n",
    "    \n",
    "    model.load_state_dict(checkpoint['model_state_dict'])\n",
    "    \n",
    "    print(f\"–ú–æ–¥–µ–ª—å –∑–∞–≥—Ä—É–∂–µ–Ω–∞ –∏–∑ {filepath}\")\n",
    "    \n",
    "    return model\n",
    "\n",
    "\n",
    "encoder_config = {\n",
    "    'vocab_size': VOCAB_SIZE,\n",
    "    'n_layers': N_LAYERS,\n",
    "    'embedding_size': EMBEDDING_SIZE,\n",
    "    'num_heads': NUM_HEADS,\n",
    "    'head_embedding_size': HEAD_EMBEDDING_SIZE,\n",
    "    'fcnn_hidden_size': FCCN_HIDDEN_SIZE,\n",
    "}\n",
    "\n",
    "loaded_model = load_model('chord_bert_model.pth', Encoder, encoder_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "db3726cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BERTLM(\n",
       "  (_encoder): Encoder(\n",
       "    (_embeddings): BERTEmbedding(\n",
       "      (_embeddings): Embedding(1213, 64, padding_idx=0)\n",
       "      (_segment_embeddings): Embedding(3, 64, padding_idx=0)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (_positional_embeddings): RotaryPositionEmbedding()\n",
       "    (_layers): ModuleList(\n",
       "      (0-5): 6 x EncoderLayer(\n",
       "        (_mha): RoPEMultiHeadedAttention(\n",
       "          (_positional_embedding): RotaryPositionEmbedding()\n",
       "          (_Q): Linear(in_features=64, out_features=64, bias=True)\n",
       "          (_K): Linear(in_features=64, out_features=64, bias=True)\n",
       "          (_V): Linear(in_features=64, out_features=64, bias=True)\n",
       "          (_W_proj): Linear(in_features=64, out_features=64, bias=True)\n",
       "          (_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (_layernorm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (_fcnn): FCNNBlock(\n",
       "          (_linear1): Linear(in_features=64, out_features=256, bias=False)\n",
       "          (_linear2): Linear(in_features=256, out_features=64, bias=False)\n",
       "          (_activation): GELU(approximate='none')\n",
       "          (_layernorm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "          (_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (_next_sentence): NextSentencePrediction(\n",
       "    (_linear): Linear(in_features=64, out_features=2, bias=True)\n",
       "    (_softmax): LogSoftmax(dim=-1)\n",
       "  )\n",
       "  (_mask_lm): MaskedLanguageModel(\n",
       "    (_linear): Linear(in_features=64, out_features=1213, bias=True)\n",
       "    (_softmax): LogSoftmax(dim=-1)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loaded_model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "efbd2442",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_masked_chord(model, tokenizer, chord_sequence):\n",
    "    \"\"\"\n",
    "    –ü—Ä–µ–¥—Å–∫–∞–∑—ã–≤–∞–µ—Ç –∞–∫–∫–æ—Ä–¥ –Ω–∞ –º–µ—Å—Ç–µ –∑–Ω–∞–∫–∞ –≤–æ–ø—Ä–æ—Å–∞ –≤ –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç–∏\n",
    "    –ü—Ä–∏–º–µ—Ä: [\"A\", \"B\", \"?\", \"B\", \"D\"] -> –ø—Ä–µ–¥—Å–∫–∞–∑—ã–≤–∞–µ—Ç –∞–∫–∫–æ—Ä–¥ –≤–º–µ—Å—Ç–æ '?'\n",
    "    \"\"\"\n",
    "\n",
    "    print(f'Input {chord_sequence}')\n",
    "    chord_sequence = chord_sequence.split()\n",
    "    masked_sequence = [chord if chord != '?' else tokenizer._mask_token for chord in chord_sequence]\n",
    "    if tokenizer._mask_token not in masked_sequence:\n",
    "        masked_sequence.append(tokenizer._mask_token)\n",
    "\n",
    "    input_ids = tokenizer.tokenize_ids(masked_sequence)\n",
    "    input_ids = [i[1] for i in input_ids]\n",
    "\n",
    "\n",
    "    inputs = torch.tensor([input_ids])\n",
    "\n",
    "    mask_index = input_ids.index(tokenizer.mask_token_id)\n",
    "    segment_label = torch.zeros_like(inputs)\n",
    "    # –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ\n",
    "    with torch.no_grad():\n",
    "        outputs = model(inputs, segment_label)\n",
    "        predictions = outputs.logits if hasattr(outputs, 'logits') else outputs\n",
    "\n",
    "    predicted_index = torch.argmax(predictions[1][0][mask_index]).item()\n",
    "    predicted_chord = tokenizer.vocab.get(predicted_index, tokenizer._unknown_token)\n",
    "    masked_sequence[mask_index] = predicted_chord\n",
    "    separator = \" \"\n",
    "    result = separator.join(masked_sequence)\n",
    "    print(f'Result {result}')\n",
    "    return predicted_chord, result, predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "52c5d627",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input D C D F B B F B B F B ? F D F C D D C D D F\n",
      "Result D C D F B B F B B F B G F D F C D D C D D F\n"
     ]
    }
   ],
   "source": [
    "predicted_chord, result, predictions = predict_masked_chord(loaded_model, loaded_tokenizer, 'D C D F B B F B B F B ? F D F C D D C D D F')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3227896",
   "metadata": {},
   "source": [
    "### –ü–æ–¥–Ω–∏–º–∞–µ–º gradio"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f280ee49",
   "metadata": {},
   "source": [
    "### –¥–ª—è –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è –∂–∞–Ω—Ä–∞"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "5480e635",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input D ? D F B B F B B F B B F D F C D D C D F\n",
      "Result D G D F B B F B B F B B F D F C D D C D F\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModel\n",
    "bert_model = AutoModel.from_pretrained(\"prajjwal1/bert-mini\")\n",
    "\n",
    "hidden_dim = 128\n",
    "num_classes = 15\n",
    "\n",
    "model_genre = ChordBERTMiniLSTMClassifier(\n",
    "    bert_model=bert_model,\n",
    "    hidden_dim=hidden_dim,\n",
    "    num_classes=num_classes,\n",
    "    dropout=0.3\n",
    ")\n",
    "\n",
    "MODEL_PATH = 'bert_model_genre.pt'\n",
    "state_dict = torch.load(MODEL_PATH, map_location=\"cpu\")\n",
    "model_genre.load_state_dict(state_dict)\n",
    "\n",
    "model_genre.eval()\n",
    "\n",
    "def predict_genres(model, tokenizer, chord_sequence, threshold=0.5):\n",
    "    \"\"\"\n",
    "    –î–µ–ª–∞–µ—Ç –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ –∂–∞–Ω—Ä–æ–≤ –Ω–∞ –æ—Å–Ω–æ–≤–µ –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ –∞–∫–∫–æ—Ä–¥–æ–≤.\n",
    "    –ú–æ–¥–µ–ª—å ‚Äî multilabel classifier.\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "\n",
    "    inputs = tokenizer(\n",
    "        chord_sequence,\n",
    "        return_tensors='pt',\n",
    "        padding=True,\n",
    "        truncation=True,\n",
    "        max_length=128\n",
    "    )\n",
    "\n",
    "    with torch.no_grad():\n",
    "        logits = model(\n",
    "            input_ids=inputs[\"input_ids\"],\n",
    "            attention_mask=inputs[\"attention_mask\"]\n",
    "        )\n",
    "\n",
    "    logits = logits[0]             \n",
    "    probs = torch.sigmoid(logits) \n",
    "\n",
    "    predicted = (probs > threshold).int().tolist()\n",
    "    all_genres = ['children / family', 'classical', 'electronic / edm', 'folk / country', 'hip hop / rap',\n",
    "                    'jazz / blues', 'latin / world', 'metal', 'other / misc', 'pop', 'punk / hardcore', 'r&b / soul',\n",
    "            'religious / worship', 'rock', 'soundtrack / score / instrumental']\n",
    "    predicted_genres = [all_genres[i] for i in range(len(all_genres)) if predicted[i] == 1]\n",
    "    return predicted_genres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "c2881dfc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/venv/lib/python3.12/site-packages/gradio/interface.py:415: UserWarning: The `allow_flagging` parameter in `Interface` is deprecated. Use `flagging_mode` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7865\n",
      "* To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7865/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input D C D F B B F B B F B B F D F C D D C ? F\n",
      "Result D C D F B B F B B F B B F D F C D D C C F\n",
      "Input D C D F B B F B B F B B F D F C D D C ? F\n",
      "Result D C D F B B F B B F B B F D F C D D C C F\n"
     ]
    }
   ],
   "source": [
    "import gradio as gr\n",
    "import numpy as np\n",
    "import io\n",
    "import wave\n",
    "import random\n",
    "\n",
    "\n",
    "# –°–∏–Ω—Ç–µ–∑ –≥–∏—Ç–∞—Ä–Ω–æ–≥–æ –∑–≤—É–∫–∞ \n",
    "SAMPLE_RATE = 22050\n",
    "\n",
    "NOTE_FREQS = {\n",
    "    'C': 261.6, 'C#': 277.2, 'Db': 277.2,\n",
    "    'D': 293.7, 'D#': 311.1, 'Eb': 311.1,\n",
    "    'E': 329.6, 'F': 349.2, 'F#': 370.0,\n",
    "    'Gb': 370.0, 'G': 392.0, 'G#': 415.3,\n",
    "    'Ab': 415.3, 'A': 440.0, 'A#': 466.2,\n",
    "    'Bb': 466.2, 'B': 493.9\n",
    "}\n",
    "\n",
    "INTERVALS = {\n",
    "    'maj': [0, 4, 7],\n",
    "    'min': [0, 3, 7],\n",
    "    'dim': [0, 3, 6],\n",
    "    'aug': [0, 4, 8],\n",
    "    '7': [0, 4, 7, 10],\n",
    "    'maj7': [0, 4, 7, 11],\n",
    "    'm7': [0, 3, 7, 10],\n",
    "    'sus2': [0, 2, 7],\n",
    "    'sus4': [0, 5, 7],\n",
    "    '5': [0, 7]\n",
    "}\n",
    "\n",
    "def parse_chord(chord):\n",
    "    chord = chord.strip()\n",
    "    root = ''\n",
    "    quality = ''\n",
    "    for note in sorted(NOTE_FREQS.keys(), key=lambda x: -len(x)):\n",
    "        if chord.startswith(note):\n",
    "            root = note\n",
    "            quality = chord[len(note):]\n",
    "            break\n",
    "    if quality == '':\n",
    "        quality = 'maj'\n",
    "    if quality in ['m', 'min']:\n",
    "        quality = 'min'\n",
    "    elif quality in ['maj', '']:\n",
    "        quality = 'maj'\n",
    "    if quality not in INTERVALS:\n",
    "        quality = 'maj'\n",
    "    return root, quality\n",
    "\n",
    "def chord_to_wave_guitar(chord, duration=1.1):\n",
    "    root, quality = parse_chord(chord)\n",
    "    base_freq = NOTE_FREQS.get(root, 261.6)\n",
    "    intervals = INTERVALS[quality]\n",
    "\n",
    "    t = np.linspace(0, duration, int(SAMPLE_RATE * duration), False)\n",
    "    wave_data = np.zeros_like(t)\n",
    "    for interval in intervals:\n",
    "        freq = base_freq * 2 ** (interval / 12)\n",
    "        envelope = np.exp(-3 * t)  # –≥–∏—Ç–∞—Ä–Ω–æ–µ –∑–∞—Ç—É—Ö–∞–Ω–∏–µ\n",
    "        wave_data += 0.3 * np.sin(2 * np.pi * freq * t) * envelope\n",
    "\n",
    "    wave_data = wave_data / np.max(np.abs(wave_data))\n",
    "    pcm = (wave_data * 32767).astype(np.int16)\n",
    "\n",
    "    buf = io.BytesIO()\n",
    "    with wave.open(buf, \"wb\") as wf:\n",
    "        wf.setnchannels(1)\n",
    "        wf.setsampwidth(2)\n",
    "        wf.setframerate(SAMPLE_RATE)\n",
    "        wf.writeframes(pcm.tobytes())\n",
    "    return buf.getvalue()\n",
    "\n",
    "def sequence_to_audio(chords: str):\n",
    "    chunks = [chord_to_wave_guitar(ch) for ch in chords.split()]\n",
    "    full = io.BytesIO()\n",
    "    with wave.open(full, \"wb\") as wf:\n",
    "        wf.setnchannels(1)\n",
    "        wf.setsampwidth(2)\n",
    "        wf.setframerate(SAMPLE_RATE)\n",
    "        for w in chunks:\n",
    "            wf.writeframes(wave.open(io.BytesIO(w)).readframes(99999999))\n",
    "    return full.getvalue()\n",
    "\n",
    "\n",
    "def predict_chords(user_input, predict_genre_flag):\n",
    "    result_chords = predict_masked_chord(loaded_model, loaded_tokenizer, user_input)[1]\n",
    "    audio_bytes = sequence_to_audio(result_chords)\n",
    "    if predict_genre_flag:\n",
    "        res_genre = predict_genres(model_genre, ChordTokenizerHF(loaded_tokenizer), user_input)\n",
    "        return result_chords, (SAMPLE_RATE, np.frombuffer(audio_bytes, dtype=np.int16)), res_genre\n",
    "    return result_chords, (SAMPLE_RATE, np.frombuffer(audio_bytes, dtype=np.int16)), '–ñ–∞–Ω—Ä –Ω–µ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω'\n",
    "\n",
    "\n",
    "\n",
    "iface = gr.Interface(\n",
    "    fn=predict_chords,\n",
    "    inputs=[\n",
    "        gr.Textbox(label=\"–í–≤–µ–¥–∏—Ç–µ –∞–∫–∫–æ—Ä–¥—ã\", placeholder=\"Am ? Dm E\"),\n",
    "        gr.Checkbox(label=\"–ü—Ä–µ–¥—Å–∫–∞–∑–∞—Ç—å –∂–∞–Ω—Ä\", value=False)\n",
    "    ],\n",
    "    outputs=[\n",
    "        gr.Textbox(label=\"–°–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –∞–∫–∫–æ—Ä–¥—ã\"),\n",
    "        gr.Audio(label=\"–ê—É–¥–∏–æ\", type=\"numpy\"),\n",
    "        gr.Textbox(label=\"–ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–Ω—ã–π –∂–∞–Ω—Ä\")\n",
    "    ],\n",
    "    title=\"üé∏ –ì–µ–Ω–µ—Ä–∞—Ç–æ—Ä –∞–∫–∫–æ—Ä–¥–æ–≤\", \n",
    "    allow_flagging='never'\n",
    ")\n",
    "iface.launch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a50ac58f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
