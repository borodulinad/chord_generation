{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4c4839d6",
   "metadata": {},
   "source": [
    "–í —ç—Ç–æ–º –Ω–æ—É—Ç–±—É–∫–µ –ø—Ä–µ–¥—Å—Ç–∞–≤–ª–µ–Ω –ø—Ä–∏–º–µ—Ä –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è, –∞ —Ç–∞–∫–∂–µ —Ä–∞–∑–≤–µ—Ä—Ç—ã–≤–∞–Ω–∏–µ —Å–µ—Ä–≤–∏—Å–∞ –ø–æ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –∞–∫–∫–æ—Ä–¥–æ–≤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ae0664ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import random\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.optim import Adam, AdamW\n",
    "from tqdm import tqdm\n",
    "import re\n",
    "from typing import List, Tuple, Optional, Mapping,  Self, NamedTuple\n",
    "import pandas as pd\n",
    "from datasets import load_dataset\n",
    "import ast\n",
    "import itertools\n",
    "import warnings\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.decomposition import PCA\n",
    "from transformers import BertTokenizer, BertForMaskedLM\n",
    "from chord_tokenaizer import ChordTokenizer, ChordTokenizerHF\n",
    "from bert_architecture import Encoder, BERTLM_MLM_And_Genre\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0ca70a97",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_and_clean_dataset():\n",
    "\n",
    "    dataset = load_dataset(\"lluccardoner/melodyGPT-song-chords-text-1\")\n",
    "    df = dataset['train'].to_pandas()\n",
    "\n",
    "    def clean_chords(text):\n",
    "        if not isinstance(text, str):\n",
    "            return \"\"\n",
    "\n",
    "        text = re.sub(r'\\t', ' ', text)\n",
    "        text = re.sub(r'\\b(INTRO|VERSE|CHORUS|BRIDGE|OUTRO|SOLO|PRE-CHORUS)\\b', '', text, flags=re.IGNORECASE)\n",
    "        chords = re.findall(r'[A-G][#b]?(?:m)?(?:1[0-3]|[2-9])?', text)\n",
    "\n",
    "        return ' '.join(chords)\n",
    "\n",
    "    df['cleaned_chords'] = df['chords_str'].apply(clean_chords)\n",
    "\n",
    "    df = df[df['cleaned_chords'].str.len() > 0]\n",
    "\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "01ddf3c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = load_and_clean_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3ed6738b",
   "metadata": {},
   "outputs": [],
   "source": [
    "list_cleaned_chords = dataset['cleaned_chords'].map(lambda x: x.split(' '))\n",
    "\n",
    "chords_set = set()\n",
    "for row in list_cleaned_chords:\n",
    "  chords_set.update(row)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c21d0b1a",
   "metadata": {},
   "source": [
    "–ó–∞–≥—Ä—É–∑–∏–º —Ç–æ–∫–µ–Ω–∞–π–∑–µ—Ä"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "430c2cf4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "–¢–æ–∫–µ–Ω–∞–π–∑–µ—Ä –∑–∞–≥—Ä—É–∂–µ–Ω –∏–∑ chord_tokenizer.pth\n"
     ]
    }
   ],
   "source": [
    "def load_tokenizer(filepath, chord_set):\n",
    "    \"\"\"–ó–∞–≥—Ä—É–∂–∞–µ—Ç —Ç–æ–∫–µ–Ω–∞–π–∑–µ—Ä –∏–∑ —Ñ–∞–π–ª–∞\"\"\"\n",
    "    tokenizer_data = torch.load(filepath)\n",
    "    \n",
    "\n",
    "    tokenizer = ChordTokenizer(chord_set)\n",
    "\n",
    "    tokenizer.vocab = tokenizer_data['vocab']\n",
    "    tokenizer.reverse_vocab = tokenizer_data['reverse_vocab']\n",
    "    tokenizer.special_tokens = tokenizer_data['special_tokens']\n",
    "    \n",
    "    print(f\"–¢–æ–∫–µ–Ω–∞–π–∑–µ—Ä –∑–∞–≥—Ä—É–∂–µ–Ω –∏–∑ {filepath}\")\n",
    "    return tokenizer\n",
    "\n",
    "loaded_tokenizer = load_tokenizer('chord_tokenizer.pth', chords_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96be4a51",
   "metadata": {},
   "source": [
    "–ó–∞–≥—Ä—É–∑–∏–º –º–æ–¥–µ–ª—å"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6ec2ea1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "VOCAB_SIZE = len(loaded_tokenizer.vocab)\n",
    "BATCH_SIZE = 64  \n",
    "MAX_SEQ_LEN = 50 \n",
    "N_LAYERS = 4 \n",
    "EMBEDDING_SIZE = 256  \n",
    "NUM_HEADS = 8\n",
    "HEAD_EMBEDDING_SIZE = EMBEDDING_SIZE // NUM_HEADS \n",
    "FCCN_HIDDEN_SIZE = 512\n",
    "DROPOUT = 0.2\n",
    "\n",
    "n_epoch = 5 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5d2541d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = Encoder(\n",
    "    vocab_size=VOCAB_SIZE,\n",
    "    n_layers=N_LAYERS,\n",
    "    embedding_size=EMBEDDING_SIZE,\n",
    "    num_heads=NUM_HEADS,\n",
    "    fcnn_hidden_size=FCCN_HIDDEN_SIZE,\n",
    "    dropout=DROPOUT\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9a48303d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "–ú–æ–¥–µ–ª—å –∑–∞–≥—Ä—É–∂–µ–Ω–∞ –∏–∑ best_genre_bert.pth\n"
     ]
    }
   ],
   "source": [
    "def load_model(filepath, encoder_class, encoder_config):\n",
    "\n",
    "    checkpoint = torch.load(filepath, map_location='cuda:0')\n",
    "    \n",
    "    encoder = encoder_class(**encoder_config)\n",
    "    model = BERTLM_MLM_And_Genre(encoder, num_genres=15)\n",
    "    \n",
    "    model.load_state_dict(checkpoint['model_state_dict'])\n",
    "    \n",
    "    print(f\"–ú–æ–¥–µ–ª—å –∑–∞–≥—Ä—É–∂–µ–Ω–∞ –∏–∑ {filepath}\")\n",
    "    \n",
    "    return model\n",
    "\n",
    "\n",
    "encoder_config = {\n",
    "    'n_layers': N_LAYERS,\n",
    "    'num_heads': NUM_HEADS,\n",
    "    'fcnn_hidden_size': FCCN_HIDDEN_SIZE,\n",
    "    'vocab_size': VOCAB_SIZE,\n",
    "    'embedding_size': EMBEDDING_SIZE,\n",
    "}\n",
    "\n",
    "loaded_model = load_model('best_genre_bert.pth', Encoder, encoder_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "db3726cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BERTLM(\n",
       "  (_encoder): Encoder(\n",
       "    (_embeddings): BERTEmbedding(\n",
       "      (_embeddings): Embedding(1213, 64, padding_idx=0)\n",
       "      (_segment_embeddings): Embedding(3, 64, padding_idx=0)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (_positional_embeddings): RotaryPositionEmbedding()\n",
       "    (_layers): ModuleList(\n",
       "      (0-5): 6 x EncoderLayer(\n",
       "        (_mha): RoPEMultiHeadedAttention(\n",
       "          (_positional_embedding): RotaryPositionEmbedding()\n",
       "          (_Q): Linear(in_features=64, out_features=64, bias=True)\n",
       "          (_K): Linear(in_features=64, out_features=64, bias=True)\n",
       "          (_V): Linear(in_features=64, out_features=64, bias=True)\n",
       "          (_W_proj): Linear(in_features=64, out_features=64, bias=True)\n",
       "          (_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (_layernorm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (_fcnn): FCNNBlock(\n",
       "          (_linear1): Linear(in_features=64, out_features=256, bias=False)\n",
       "          (_linear2): Linear(in_features=256, out_features=64, bias=False)\n",
       "          (_activation): GELU(approximate='none')\n",
       "          (_layernorm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "          (_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (_next_sentence): NextSentencePrediction(\n",
       "    (_linear): Linear(in_features=64, out_features=2, bias=True)\n",
       "    (_softmax): LogSoftmax(dim=-1)\n",
       "  )\n",
       "  (_mask_lm): MaskedLanguageModel(\n",
       "    (_linear): Linear(in_features=64, out_features=1213, bias=True)\n",
       "    (_softmax): LogSoftmax(dim=-1)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loaded_model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "2da579cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open('cats_dict_mapping.pickle', 'rb') as file:\n",
    "    cats_dict = pickle.load(file)\n",
    "\n",
    "reverse_cat_dict = {v:k for k,v in cats_dict.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "efbd2442",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(model, tokenizer, chord_sequence, return_genre_pred=False):\n",
    "\n",
    "    model.eval()\n",
    "    \n",
    "    chord_sequence = chord_sequence.split()\n",
    "    mask_token = '[MASK]'\n",
    "    masked_sequence = [chord if chord != '?' else mask_token for chord in chord_sequence]\n",
    "    \n",
    "    if mask_token not in masked_sequence:\n",
    "        masked_sequence.append(mask_token)\n",
    "\n",
    "    input_ids = tokenizer.convert_tokens_to_ids(masked_sequence)\n",
    "    mask_index = input_ids.index(4)\n",
    "    inputs = torch.tensor(input_ids)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        inputs = inputs.unsqueeze(0)\n",
    "        if return_genre_pred:\n",
    "            mlm_output, genre_output = model(inputs, return_genre_pred)\n",
    "             \n",
    "        else:\n",
    "            mlm_output = model(inputs)\n",
    "\n",
    "\n",
    "    masked_predictions = mlm_output[0, mask_index] \n",
    "\n",
    "    predicted_index = torch.argmax(masked_predictions).item()\n",
    "    predicted_chord = tokenizer.reverse_vocab.get(predicted_index, '[UNK]')\n",
    "\n",
    "    masked_sequence[mask_index] = predicted_chord\n",
    "    result = \" \".join(masked_sequence)\n",
    "\n",
    "    if return_genre_pred:\n",
    "        pred_genre = genre_output.argmax(dim=-1).item()\n",
    "        genre = reverse_cat_dict.get(pred_genre, 'unknown')\n",
    "        return result, genre\n",
    "    else:\n",
    "        return result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "52c5d627",
   "metadata": {},
   "outputs": [],
   "source": [
    "result, genre = predict(loaded_model, loaded_tokenizer, 'D ? D F B B F B B F B B F D F C D D C D F', return_genre_pred = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "8a634e0d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'D D D F B B F B B F B B F D F C D D C D F'"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "719876c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'rock'"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "genre"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3227896",
   "metadata": {},
   "source": [
    "### –ü–æ–¥–Ω–∏–º–∞–µ–º gradio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "c2881dfc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7863\n",
      "* To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7863/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gradio as gr\n",
    "import numpy as np\n",
    "import io\n",
    "import wave\n",
    "import random\n",
    "\n",
    "\n",
    "# –°–∏–Ω—Ç–µ–∑ –≥–∏—Ç–∞—Ä–Ω–æ–≥–æ –∑–≤—É–∫–∞ \n",
    "SAMPLE_RATE = 22050\n",
    "\n",
    "NOTE_FREQS = {\n",
    "    'C': 261.6, 'C#': 277.2, 'Db': 277.2,\n",
    "    'D': 293.7, 'D#': 311.1, 'Eb': 311.1,\n",
    "    'E': 329.6, 'F': 349.2, 'F#': 370.0,\n",
    "    'Gb': 370.0, 'G': 392.0, 'G#': 415.3,\n",
    "    'Ab': 415.3, 'A': 440.0, 'A#': 466.2,\n",
    "    'Bb': 466.2, 'B': 493.9\n",
    "}\n",
    "\n",
    "INTERVALS = {\n",
    "    'maj': [0, 4, 7],\n",
    "    'min': [0, 3, 7],\n",
    "    'dim': [0, 3, 6],\n",
    "    'aug': [0, 4, 8],\n",
    "    '7': [0, 4, 7, 10],\n",
    "    'maj7': [0, 4, 7, 11],\n",
    "    'm7': [0, 3, 7, 10],\n",
    "    'sus2': [0, 2, 7],\n",
    "    'sus4': [0, 5, 7],\n",
    "    '5': [0, 7]\n",
    "}\n",
    "\n",
    "def parse_chord(chord):\n",
    "    chord = chord.strip()\n",
    "    root = ''\n",
    "    quality = ''\n",
    "    for note in sorted(NOTE_FREQS.keys(), key=lambda x: -len(x)):\n",
    "        if chord.startswith(note):\n",
    "            root = note\n",
    "            quality = chord[len(note):]\n",
    "            break\n",
    "    if quality == '':\n",
    "        quality = 'maj'\n",
    "    if quality in ['m', 'min']:\n",
    "        quality = 'min'\n",
    "    elif quality in ['maj', '']:\n",
    "        quality = 'maj'\n",
    "    if quality not in INTERVALS:\n",
    "        quality = 'maj'\n",
    "    return root, quality\n",
    "\n",
    "def chord_to_wave_guitar(chord, duration=1.1):\n",
    "    root, quality = parse_chord(chord)\n",
    "    base_freq = NOTE_FREQS.get(root, 261.6)\n",
    "    intervals = INTERVALS[quality]\n",
    "\n",
    "    t = np.linspace(0, duration, int(SAMPLE_RATE * duration), False)\n",
    "    wave_data = np.zeros_like(t)\n",
    "    for interval in intervals:\n",
    "        freq = base_freq * 2 ** (interval / 12)\n",
    "        envelope = np.exp(-3 * t)  # –≥–∏—Ç–∞—Ä–Ω–æ–µ –∑–∞—Ç—É—Ö–∞–Ω–∏–µ\n",
    "        wave_data += 0.3 * np.sin(2 * np.pi * freq * t) * envelope\n",
    "\n",
    "    wave_data = wave_data / np.max(np.abs(wave_data))\n",
    "    pcm = (wave_data * 32767).astype(np.int16)\n",
    "\n",
    "    buf = io.BytesIO()\n",
    "    with wave.open(buf, \"wb\") as wf:\n",
    "        wf.setnchannels(1)\n",
    "        wf.setsampwidth(2)\n",
    "        wf.setframerate(SAMPLE_RATE)\n",
    "        wf.writeframes(pcm.tobytes())\n",
    "    return buf.getvalue()\n",
    "\n",
    "def sequence_to_audio(chords: str):\n",
    "    chunks = [chord_to_wave_guitar(ch) for ch in chords.split()]\n",
    "    full = io.BytesIO()\n",
    "    with wave.open(full, \"wb\") as wf:\n",
    "        wf.setnchannels(1)\n",
    "        wf.setsampwidth(2)\n",
    "        wf.setframerate(SAMPLE_RATE)\n",
    "        for w in chunks:\n",
    "            wf.writeframes(wave.open(io.BytesIO(w)).readframes(99999999))\n",
    "    return full.getvalue()\n",
    "\n",
    "\n",
    "def predict_chords(user_input, predict_genre_flag):\n",
    "    if predict_genre_flag:\n",
    "        result_chords, res_genre = predict(loaded_model, loaded_tokenizer, user_input, return_genre_pred=True)\n",
    "        audio_bytes = sequence_to_audio(result_chords)\n",
    "    else:\n",
    "        result_chords = predict(loaded_model, loaded_tokenizer, user_input)\n",
    "        audio_bytes = sequence_to_audio(result_chords)\n",
    "        res_genre = '–ñ–∞–Ω—Ä –Ω–µ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω'\n",
    "    return result_chords, (SAMPLE_RATE, np.frombuffer(audio_bytes, dtype=np.int16)), res_genre\n",
    "\n",
    "\n",
    "\n",
    "iface = gr.Interface(\n",
    "    fn=predict_chords,\n",
    "    inputs=[\n",
    "        gr.Textbox(label=\"–í–≤–µ–¥–∏—Ç–µ –∞–∫–∫–æ—Ä–¥—ã\", placeholder=\"Am ? Dm E\"),\n",
    "        gr.Checkbox(label=\"–ü—Ä–µ–¥—Å–∫–∞–∑–∞—Ç—å –∂–∞–Ω—Ä\", value=False)\n",
    "    ],\n",
    "    outputs=[\n",
    "        gr.Textbox(label=\"–°–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –∞–∫–∫–æ—Ä–¥—ã\"),\n",
    "        gr.Audio(label=\"–ê—É–¥–∏–æ\", type=\"numpy\"),\n",
    "        gr.Textbox(label=\"–ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–Ω—ã–π –∂–∞–Ω—Ä\")\n",
    "    ],\n",
    "    title=\"üé∏ –ì–µ–Ω–µ—Ä–∞—Ç–æ—Ä –∞–∫–∫–æ—Ä–¥–æ–≤\", \n",
    "    allow_flagging='never'\n",
    ")\n",
    "iface.launch()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
